{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bharatgaur/Projects/blob/main/AI%20Video%20Creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-pptx gtts opencv-python pydub pillow moviepy"
      ],
      "metadata": {
        "id": "mbNp06BL3LtF",
        "outputId": "bb8f68d5-d700-4821-9528-ae306b015a82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-pptx\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
            "  Downloading XlsxWriter-3.2.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (4.12.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gtts) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gtts) (8.1.8)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (2025.1.31)\n",
            "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading XlsxWriter-3.2.2-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, XlsxWriter, python-pptx, gtts\n",
            "Successfully installed XlsxWriter-3.2.2 gtts-2.5.4 pydub-0.25.1 python-pptx-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image"
      ],
      "metadata": {
        "id": "o2n9t23x8CGA",
        "outputId": "44fe1d7f-e8a0-4eb7-b755-b636a66ba040",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.1.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install poppler-utils"
      ],
      "metadata": {
        "id": "JDMpeJhM84mW",
        "outputId": "4964deac-4f2b-4ed6-e858-118c2fd5bdac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.6 [186 kB]\n",
            "Fetched 186 kB in 1s (249 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 124926 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.6_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# trying to fixing the error\n",
        "# Error to fix ho gaya but ye kuch symbolls ko bol rahi thi hash underscore\n",
        "import os\n",
        "from pptx import Presentation\n",
        "from gtts import gTTS\n",
        "import moviepy.editor as mp\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "# === Step 1: Convert PPT to PDF and Extract Images ===\n",
        "ppt_file = \"/content/OOP_Introduction_Python.pptx\"\n",
        "pdf_file = \"/content/OOP_Introduction_Python.pdf\"\n",
        "output_folder = \"output\"\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Convert PPTX to PDF using LibreOffice (works in Colab)\n",
        "!soffice --headless --convert-to pdf \"{ppt_file}\" --outdir \"/content\"\n",
        "\n",
        "# Convert PDF pages to images (each slide as an image)\n",
        "slides = convert_from_path(pdf_file)\n",
        "image_files = []\n",
        "for i, slide in enumerate(slides):\n",
        "    image_path = f\"{output_folder}/slide_{i+1}.png\"\n",
        "    slide.save(image_path, \"PNG\")\n",
        "    image_files.append(image_path)\n",
        "\n",
        "# === Step 2: Generate Audio for Each Slide ===\n",
        "audio_files = []\n",
        "for i, img_path in enumerate(image_files):\n",
        "    slide_text = input(f\"Enter narration text for Slide {i+1}: \")\n",
        "\n",
        "    # Convert text to speech\n",
        "    audio_path = f\"{output_folder}/slide_{i+1}.mp3\"\n",
        "    tts = gTTS(text=slide_text, lang=\"en\")\n",
        "    tts.save(audio_path)\n",
        "    audio_files.append(audio_path)\n",
        "\n",
        "# === Step 3: Create Video ===\n",
        "video_clips = []\n",
        "for img_path, audio_path in zip(image_files, audio_files):\n",
        "    image_clip = mp.ImageClip(img_path).set_duration(mp.AudioFileClip(audio_path).duration)\n",
        "    audio_clip = mp.AudioFileClip(audio_path)\n",
        "    video_clips.append(image_clip.set_audio(audio_clip))\n",
        "\n",
        "# Combine all clips\n",
        "final_video = mp.concatenate_videoclips(video_clips, method=\"compose\")\n",
        "\n",
        "# Save final video\n",
        "video_output_path = \"final_presentation.mp4\"\n",
        "final_video.write_videofile(video_output_path, codec=\"libx264\", fps=24)\n",
        "\n",
        "print(f\"🎥 Video created successfully: {video_output_path}\")\n"
      ],
      "metadata": {
        "id": "2qrqNHK13Lnx",
        "outputId": "d4354986-b000-4213-9e16-a36ff4c055b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: soffice: command not found\n",
            "Enter narration text for Slide 1: \"Introduction to Object-Oriented Programming (OOP) in Python\"   \"Hello everyone! Welcome to this session on Object-Oriented Programming (OOP) in Python. Today, we will dive into the fundamental concepts of OOP, why it is important, and how we can use it effectively in Python. Whether you are a beginner or someone looking to refine your knowledge, this session will help you get a clear understanding of OOP. So, let’s begin!\"\n",
            "Enter narration text for Slide 2: What is OOP? \"OOP is a programming paradigm based on objects, which contain data and methods.\"   \"Object-Oriented Programming, or OOP, is a programming approach that organizes code around objects and classes instead of just functions and logic. Each object represents a real-world entity, holding data (attributes) and performing actions (methods). For example, think about a Car. A car has properties like color, brand, and model, and it can perform actions like drive, brake, or accelerate. These properties and actions define an object. By using OOP, we make our programs more modular, reusable, and scalable, which makes coding efficient and organized.\"\n",
            "Enter narration text for Slide 3: Why Use OOP? \"OOP provides modularity, reusability, scalability, and maintainability.\"   \"Now, why should we use OOP? Modularity – It breaks large, complex problems into smaller parts, making the code easier to understand. Reusability – We can reuse code by creating classes and objects instead of writing the same logic again. Scalability – It is easier to add new features without affecting existing code. Maintainability – Debugging and updating code becomes simple. Real-world modeling – OOP closely represents how objects behave in real life. For example, in a large e-commerce application, every user can be an object, with attributes like name, email, and orders. Instead of writing code separately for each user, we define a class once and create multiple objects from it.\"\n",
            "Enter narration text for Slide 4: Core Concepts of OOP \"The key concepts of OOP are Class, Object, Encapsulation, Inheritance, Polymorphism, and Abstraction.\"   \"OOP is built around six core concepts: Class – Think of it as a blueprint for creating objects. Object – An instance of a class that holds data and methods. Encapsulation – Hiding data to prevent direct access and making code more secure. Inheritance – Allowing one class to reuse properties and methods of another class. Polymorphism – The same function name can be used for different purposes. Abstraction – Hiding complex implementation details and showing only the necessary information. These concepts make OOP powerful and flexible!\"\n",
            "Enter narration text for Slide 5: OOP in Python - Basic Syntax \"Example: Creating a simple Car class in Python.\"   \"Now, let’s look at a basic Python example that demonstrates OOP. class Car:     def __init__(self, brand, color):         self.brand = brand  # Attribute         self.color = color  # Attribute          def drive(self):         print(f\"The {self.color} {self.brand} is driving.\")  # Method  # Creating an object my_car = Car(\"Tesla\", \"Red\") my_car.drive()  # Output: The Red Tesla is driving.  Here, ‘Car’ is a class, which acts as a blueprint. We define attributes (brand, color) and a method (drive). Then, we create an object ‘my_car’ with values (\"Tesla\", \"Red\"). Calling the drive() method prints a message related to the object. This is how we create and use objects in Python!\"\n",
            "Enter narration text for Slide 6: Real-World Example \"OOP concepts in a Banking System.\"   \"Let’s take a real-world example of a Banking System. A BankAccount is a class that defines accounts. Every customer has an account object with attributes like account number and balance. Methods like deposit(), withdraw(), and check_balance() define actions users can take. Encapsulation keeps user data private. Inheritance allows creating specialized accounts, like SavingsAccount and CurrentAccount. Polymorphism lets different account types have different interest rates. This example shows how OOP makes software systems structured, secure, and easy to maintain.\"\n",
            "Enter narration text for Slide 7: Conclusion \"OOP enhances code structure and improves efficiency.\"   \"So, to wrap up, Object-Oriented Programming (OOP) makes software development more structured, reusable, and scalable. Python’s OOP features allow us to build efficient applications, whether it's for web development, game development, or machine learning. To master OOP, start practicing by writing your own classes and objects. Try creating a Student Management System, a Library System, or a simple game using OOP principles. Thank you for your time, and I hope this session has given you a solid understanding of OOP in Python!\"\n",
            "Moviepy - Building video final_presentation.mp4.\n",
            "MoviePy - Writing audio in final_presentationTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_presentation.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready final_presentation.mp4\n",
            "🎥 Video created successfully: final_presentation.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import gtts\n",
        "import moviepy.editor as mp\n",
        "from pptx import Presentation\n",
        "from pdf2image import convert_from_path\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "\n",
        "# === Step 1: Convert PPT to PDF and Extract Images ===\n",
        "ppt_file = \"/content/OOP_Introduction_Python.pptx\"\n",
        "pdf_file = \"/content/OOP_Introduction_Python.pdf\"\n",
        "output_folder = \"output\"\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Convert PPTX to PDF using LibreOffice\n",
        "os.system(f'soffice --headless --convert-to pdf \"{ppt_file}\" --outdir \"/content\"')\n",
        "\n",
        "# Convert PDF pages to images (each slide as an image)\n",
        "slides = convert_from_path(pdf_file)\n",
        "image_files = []\n",
        "for i, slide in enumerate(slides):\n",
        "    image_path = f\"{output_folder}/slide_{i+1}.png\"\n",
        "    slide.save(image_path, \"PNG\")\n",
        "    image_files.append(image_path)\n",
        "\n",
        "# === Step 2: Generate Audio for Each Slide (Deep Male Voice) ===\n",
        "def clean_text(text):\n",
        "    \"\"\" Remove unwanted symbols from text. \"\"\"\n",
        "    text = re.sub(r'[_\"#*<>@{}[\\]()/\\\\]', '', text)  # Remove unwanted symbols\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "audio_files = []\n",
        "for i, img_path in enumerate(image_files):\n",
        "    slide_text = input(f\"Enter narration text for Slide {i+1}: \")\n",
        "    slide_text = clean_text(slide_text)\n",
        "\n",
        "    # Convert text to speech (Deep Male Voice)\n",
        "    audio_path = f\"{output_folder}/slide_{i+1}.mp3\"\n",
        "    tts = gtts.gTTS(text=slide_text, lang=\"en\", slow=False)\n",
        "    tts.save(audio_path)\n",
        "\n",
        "    # Lower the pitch (Make it sound more male-like)\n",
        "    sound = AudioSegment.from_file(audio_path)\n",
        "    deep_voice = sound._spawn(sound.raw_data, overrides={\n",
        "        \"frame_rate\": int(sound.frame_rate * 0.8)  # Lower pitch\n",
        "    }).set_frame_rate(sound.frame_rate)\n",
        "    deep_voice.export(audio_path, format=\"mp3\")\n",
        "\n",
        "    audio_files.append(audio_path)\n",
        "\n",
        "# === Step 3: Create Video ===\n",
        "video_clips = []\n",
        "for img_path, audio_path in zip(image_files, audio_files):\n",
        "    image_clip = mp.ImageClip(img_path).set_duration(mp.AudioFileClip(audio_path).duration)\n",
        "    audio_clip = mp.AudioFileClip(audio_path)\n",
        "    video_clips.append(image_clip.set_audio(audio_clip))\n",
        "\n",
        "# Combine all clips\n",
        "final_video = mp.concatenate_videoclips(video_clips, method=\"compose\")\n",
        "\n",
        "# Save final video\n",
        "video_output_path = \"final_presentation.mp4\"\n",
        "final_video.write_videofile(video_output_path, codec=\"libx264\", fps=24)\n",
        "\n",
        "print(f\"🎥 Video created successfully: {video_output_path}\")"
      ],
      "metadata": {
        "id": "e6coir5P3LkQ",
        "outputId": "d160ca4f-6ae3-4de3-8512-fbcaae849de8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter narration text for Slide 1: \"Hello everyone! Welcome to this session on Object-Oriented Programming (OOP) in Python. Today, we will dive into the fundamental concepts of OOP, why it is important, and how we can use it effectively in Python. Whether you are a beginner or someone looking to refine your knowledge, this session will help you get a clear understanding of OOP. So, let’s begin!\"\n",
            "Enter narration text for Slide 2: What is OOP? \"OOP is a programming paradigm based on objects, which contain data and methods.\"   \"Object-Oriented Programming, or OOP, is a programming approach that organizes code around objects and classes instead of just functions and logic. Each object represents a real-world entity, holding data (attributes) and performing actions (methods). For example, think about a Car. A car has properties like color, brand, and model, and it can perform actions like drive, brake, or accelerate. These properties and actions define an object. By using OOP, we make our programs more modular, reusable, and scalable, which makes coding efficient and organized.\"\n",
            "Enter narration text for Slide 3: Why Use OOP? \"OOP provides modularity, reusability, scalability, and maintainability.\"   \"Now, why should we use OOP? Modularity – It breaks large, complex problems into smaller parts, making the code easier to understand. Reusability – We can reuse code by creating classes and objects instead of writing the same logic again. Scalability – It is easier to add new features without affecting existing code. Maintainability – Debugging and updating code becomes simple. Real-world modeling – OOP closely represents how objects behave in real life. For example, in a large e-commerce application, every user can be an object, with attributes like name, email, and orders. Instead of writing code separately for each user, we define a class once and create multiple objects from it.\"\n",
            "Enter narration text for Slide 4: Core Concepts of OOP \"The key concepts of OOP are Class, Object, Encapsulation, Inheritance, Polymorphism, and Abstraction.\"   \"OOP is built around six core concepts: Class – Think of it as a blueprint for creating objects. Object – An instance of a class that holds data and methods. Encapsulation – Hiding data to prevent direct access and making code more secure. Inheritance – Allowing one class to reuse properties and methods of another class. Polymorphism – The same function name can be used for different purposes. Abstraction – Hiding complex implementation details and showing only the necessary information. These concepts make OOP powerful and flexible!\"\n",
            "Enter narration text for Slide 5: OOP in Python - Basic Syntax \"Example: Creating a simple Car class in Python.\"   \"Now, let’s look at a basic Python example that demonstrates OOP. class Car:     def __init__(self, brand, color):         self.brand = brand  # Attribute         self.color = color  # Attribute          def drive(self):         print(f\"The {self.color} {self.brand} is driving.\")  # Method  # Creating an object my_car = Car(\"Tesla\", \"Red\") my_car.drive()  # Output: The Red Tesla is driving.  Here, ‘Car’ is a class, which acts as a blueprint. We define attributes (brand, color) and a method (drive). Then, we create an object ‘my_car’ with values (\"Tesla\", \"Red\"). Calling the drive() method prints a message related to the object. This is how we create and use objects in Python!\"\n",
            "Enter narration text for Slide 6: Real-World Example \"OOP concepts in a Banking System.\"   \"Let’s take a real-world example of a Banking System. A BankAccount is a class that defines accounts. Every customer has an account object with attributes like account number and balance. Methods like deposit(), withdraw(), and check_balance() define actions users can take. Encapsulation keeps user data private. Inheritance allows creating specialized accounts, like SavingsAccount and CurrentAccount. Polymorphism lets different account types have different interest rates. This example shows how OOP makes software systems structured, secure, and easy to maintain.\"\n",
            "Enter narration text for Slide 7: Conclusion \"OOP enhances code structure and improves efficiency.\"   \"So, to wrap up, Object-Oriented Programming (OOP) makes software development more structured, reusable, and scalable. Python’s OOP features allow us to build efficient applications, whether it's for web development, game development, or machine learning. To master OOP, start practicing by writing your own classes and objects. Try creating a Student Management System, a Library System, or a simple game using OOP principles. Thank you for your time, and I hope this session has given you a solid understanding of OOP in Python!\"\n",
            "Moviepy - Building video final_presentation.mp4.\n",
            "MoviePy - Writing audio in final_presentationTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_presentation.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready final_presentation.mp4\n",
            "🎥 Video created successfully: final_presentation.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kw62RzBb3Li4",
        "outputId": "7e2dd645-cd8c-4e3c-a23d-911c2a08baa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "max() arg is an empty sequence",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-7d9e1aa63ea7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Combine all clips & Export Video with Fast Codec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mfinal_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate_videoclips\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_clips\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"compose\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0mvideo_output_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"final_presentation.mp4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mfinal_video\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_videofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_output_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"h264_nvenc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/moviepy/video/compositing/concatenate.py\u001b[0m in \u001b[0;36mconcatenate_videoclips\u001b[0;34m(clips, method, transition, bg_color, ismask, padding)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0msizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclips\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install edge-tts"
      ],
      "metadata": {
        "id": "BZrJi_wEL6MK",
        "outputId": "f3aadf96-b4b9-4f21-a459-01b064e511a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting edge-tts\n",
            "  Downloading edge_tts-7.0.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (3.11.12)\n",
            "Requirement already satisfied: certifi>=2023.11.17 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (2025.1.31)\n",
            "Collecting srt<4.0.0,>=3.4.1 (from edge-tts)\n",
            "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate<1.0.0,>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp<4.0.0,>=3.8.0->edge-tts) (3.10)\n",
            "Downloading edge_tts-7.0.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: srt\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22428 sha256=e9a49c6daccfbbb975efc63dbce842ac589f82155b411c88c9a267f9a87d717a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/43/f1/23ee9119497fcb57d9f7046fbf34c6d9027c46a1fa7824cf08\n",
            "Successfully built srt\n",
            "Installing collected packages: srt, edge-tts\n",
            "Successfully installed edge-tts-7.0.0 srt-3.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy pdf2image pydub gtts python-pptx"
      ],
      "metadata": {
        "id": "ooFdakJOMI6O",
        "outputId": "2be65f27-d8b5-45f6-ffbb-5587ae8f6938",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: gtts in /usr/local/lib/python3.11/dist-packages (2.5.4)\n",
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.11/dist-packages (1.0.2)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.1.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gtts) (8.1.8)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (3.2.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest_asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "g7TEhh-6MTVY",
        "outputId": "c6f8359d-5148-47e1-9a9e-879bb1288efc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import edge_tts\n",
        "voices = await edge_tts.list_voices()\n",
        "for voice in voices:\n",
        "    print(voice[\"ShortName\"], \"-\", voice[\"Gender\"])"
      ],
      "metadata": {
        "id": "sJe9Upr5MisK",
        "outputId": "0cecc4f9-417a-4a33-978d-f1d580b1e1a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "af-ZA-AdriNeural - Female\n",
            "af-ZA-WillemNeural - Male\n",
            "sq-AL-AnilaNeural - Female\n",
            "sq-AL-IlirNeural - Male\n",
            "am-ET-AmehaNeural - Male\n",
            "am-ET-MekdesNeural - Female\n",
            "ar-DZ-AminaNeural - Female\n",
            "ar-DZ-IsmaelNeural - Male\n",
            "ar-BH-AliNeural - Male\n",
            "ar-BH-LailaNeural - Female\n",
            "ar-EG-SalmaNeural - Female\n",
            "ar-EG-ShakirNeural - Male\n",
            "ar-IQ-BasselNeural - Male\n",
            "ar-IQ-RanaNeural - Female\n",
            "ar-JO-SanaNeural - Female\n",
            "ar-JO-TaimNeural - Male\n",
            "ar-KW-FahedNeural - Male\n",
            "ar-KW-NouraNeural - Female\n",
            "ar-LB-LaylaNeural - Female\n",
            "ar-LB-RamiNeural - Male\n",
            "ar-LY-ImanNeural - Female\n",
            "ar-LY-OmarNeural - Male\n",
            "ar-MA-JamalNeural - Male\n",
            "ar-MA-MounaNeural - Female\n",
            "ar-OM-AbdullahNeural - Male\n",
            "ar-OM-AyshaNeural - Female\n",
            "ar-QA-AmalNeural - Female\n",
            "ar-QA-MoazNeural - Male\n",
            "ar-SA-HamedNeural - Male\n",
            "ar-SA-ZariyahNeural - Female\n",
            "ar-SY-AmanyNeural - Female\n",
            "ar-SY-LaithNeural - Male\n",
            "ar-TN-HediNeural - Male\n",
            "ar-TN-ReemNeural - Female\n",
            "ar-AE-FatimaNeural - Female\n",
            "ar-AE-HamdanNeural - Male\n",
            "ar-YE-MaryamNeural - Female\n",
            "ar-YE-SalehNeural - Male\n",
            "az-AZ-BabekNeural - Male\n",
            "az-AZ-BanuNeural - Female\n",
            "bn-BD-NabanitaNeural - Female\n",
            "bn-BD-PradeepNeural - Male\n",
            "bn-IN-BashkarNeural - Male\n",
            "bn-IN-TanishaaNeural - Female\n",
            "bs-BA-VesnaNeural - Female\n",
            "bs-BA-GoranNeural - Male\n",
            "bg-BG-BorislavNeural - Male\n",
            "bg-BG-KalinaNeural - Female\n",
            "my-MM-NilarNeural - Female\n",
            "my-MM-ThihaNeural - Male\n",
            "ca-ES-EnricNeural - Male\n",
            "ca-ES-JoanaNeural - Female\n",
            "zh-HK-HiuGaaiNeural - Female\n",
            "zh-HK-HiuMaanNeural - Female\n",
            "zh-HK-WanLungNeural - Male\n",
            "zh-CN-XiaoxiaoNeural - Female\n",
            "zh-CN-XiaoyiNeural - Female\n",
            "zh-CN-YunjianNeural - Male\n",
            "zh-CN-YunxiNeural - Male\n",
            "zh-CN-YunxiaNeural - Male\n",
            "zh-CN-YunyangNeural - Male\n",
            "zh-CN-liaoning-XiaobeiNeural - Female\n",
            "zh-TW-HsiaoChenNeural - Female\n",
            "zh-TW-YunJheNeural - Male\n",
            "zh-TW-HsiaoYuNeural - Female\n",
            "zh-CN-shaanxi-XiaoniNeural - Female\n",
            "hr-HR-GabrijelaNeural - Female\n",
            "hr-HR-SreckoNeural - Male\n",
            "cs-CZ-AntoninNeural - Male\n",
            "cs-CZ-VlastaNeural - Female\n",
            "da-DK-ChristelNeural - Female\n",
            "da-DK-JeppeNeural - Male\n",
            "nl-BE-ArnaudNeural - Male\n",
            "nl-BE-DenaNeural - Female\n",
            "nl-NL-ColetteNeural - Female\n",
            "nl-NL-FennaNeural - Female\n",
            "nl-NL-MaartenNeural - Male\n",
            "en-AU-NatashaNeural - Female\n",
            "en-AU-WilliamNeural - Male\n",
            "en-CA-ClaraNeural - Female\n",
            "en-CA-LiamNeural - Male\n",
            "en-HK-YanNeural - Female\n",
            "en-HK-SamNeural - Male\n",
            "en-IN-NeerjaExpressiveNeural - Female\n",
            "en-IN-NeerjaNeural - Female\n",
            "en-IN-PrabhatNeural - Male\n",
            "en-IE-ConnorNeural - Male\n",
            "en-IE-EmilyNeural - Female\n",
            "en-KE-AsiliaNeural - Female\n",
            "en-KE-ChilembaNeural - Male\n",
            "en-NZ-MitchellNeural - Male\n",
            "en-NZ-MollyNeural - Female\n",
            "en-NG-AbeoNeural - Male\n",
            "en-NG-EzinneNeural - Female\n",
            "en-PH-JamesNeural - Male\n",
            "en-PH-RosaNeural - Female\n",
            "en-US-AvaNeural - Female\n",
            "en-US-AndrewNeural - Male\n",
            "en-US-EmmaNeural - Female\n",
            "en-US-BrianNeural - Male\n",
            "en-SG-LunaNeural - Female\n",
            "en-SG-WayneNeural - Male\n",
            "en-ZA-LeahNeural - Female\n",
            "en-ZA-LukeNeural - Male\n",
            "en-TZ-ElimuNeural - Male\n",
            "en-TZ-ImaniNeural - Female\n",
            "en-GB-LibbyNeural - Female\n",
            "en-GB-MaisieNeural - Female\n",
            "en-GB-RyanNeural - Male\n",
            "en-GB-SoniaNeural - Female\n",
            "en-GB-ThomasNeural - Male\n",
            "en-US-AnaNeural - Female\n",
            "en-US-AndrewMultilingualNeural - Male\n",
            "en-US-AriaNeural - Female\n",
            "en-US-AvaMultilingualNeural - Female\n",
            "en-US-BrianMultilingualNeural - Male\n",
            "en-US-ChristopherNeural - Male\n",
            "en-US-EmmaMultilingualNeural - Female\n",
            "en-US-EricNeural - Male\n",
            "en-US-GuyNeural - Male\n",
            "en-US-JennyNeural - Female\n",
            "en-US-MichelleNeural - Female\n",
            "en-US-RogerNeural - Male\n",
            "en-US-SteffanNeural - Male\n",
            "et-EE-AnuNeural - Female\n",
            "et-EE-KertNeural - Male\n",
            "fil-PH-AngeloNeural - Male\n",
            "fil-PH-BlessicaNeural - Female\n",
            "fi-FI-HarriNeural - Male\n",
            "fi-FI-NooraNeural - Female\n",
            "fr-BE-CharlineNeural - Female\n",
            "fr-BE-GerardNeural - Male\n",
            "fr-CA-ThierryNeural - Male\n",
            "fr-CA-AntoineNeural - Male\n",
            "fr-CA-JeanNeural - Male\n",
            "fr-CA-SylvieNeural - Female\n",
            "fr-FR-VivienneMultilingualNeural - Female\n",
            "fr-FR-RemyMultilingualNeural - Male\n",
            "fr-FR-DeniseNeural - Female\n",
            "fr-FR-EloiseNeural - Female\n",
            "fr-FR-HenriNeural - Male\n",
            "fr-CH-ArianeNeural - Female\n",
            "fr-CH-FabriceNeural - Male\n",
            "gl-ES-RoiNeural - Male\n",
            "gl-ES-SabelaNeural - Female\n",
            "ka-GE-EkaNeural - Female\n",
            "ka-GE-GiorgiNeural - Male\n",
            "de-AT-IngridNeural - Female\n",
            "de-AT-JonasNeural - Male\n",
            "de-DE-SeraphinaMultilingualNeural - Female\n",
            "de-DE-FlorianMultilingualNeural - Male\n",
            "de-DE-AmalaNeural - Female\n",
            "de-DE-ConradNeural - Male\n",
            "de-DE-KatjaNeural - Female\n",
            "de-DE-KillianNeural - Male\n",
            "de-CH-JanNeural - Male\n",
            "de-CH-LeniNeural - Female\n",
            "el-GR-AthinaNeural - Female\n",
            "el-GR-NestorasNeural - Male\n",
            "gu-IN-DhwaniNeural - Female\n",
            "gu-IN-NiranjanNeural - Male\n",
            "he-IL-AvriNeural - Male\n",
            "he-IL-HilaNeural - Female\n",
            "hi-IN-MadhurNeural - Male\n",
            "hi-IN-SwaraNeural - Female\n",
            "hu-HU-NoemiNeural - Female\n",
            "hu-HU-TamasNeural - Male\n",
            "is-IS-GudrunNeural - Female\n",
            "is-IS-GunnarNeural - Male\n",
            "id-ID-ArdiNeural - Male\n",
            "id-ID-GadisNeural - Female\n",
            "iu-Latn-CA-SiqiniqNeural - Female\n",
            "iu-Latn-CA-TaqqiqNeural - Male\n",
            "iu-Cans-CA-SiqiniqNeural - Female\n",
            "iu-Cans-CA-TaqqiqNeural - Male\n",
            "ga-IE-ColmNeural - Male\n",
            "ga-IE-OrlaNeural - Female\n",
            "it-IT-GiuseppeMultilingualNeural - Male\n",
            "it-IT-DiegoNeural - Male\n",
            "it-IT-ElsaNeural - Female\n",
            "it-IT-IsabellaNeural - Female\n",
            "ja-JP-KeitaNeural - Male\n",
            "ja-JP-NanamiNeural - Female\n",
            "jv-ID-DimasNeural - Male\n",
            "jv-ID-SitiNeural - Female\n",
            "kn-IN-GaganNeural - Male\n",
            "kn-IN-SapnaNeural - Female\n",
            "kk-KZ-AigulNeural - Female\n",
            "kk-KZ-DauletNeural - Male\n",
            "km-KH-PisethNeural - Male\n",
            "km-KH-SreymomNeural - Female\n",
            "ko-KR-HyunsuMultilingualNeural - Male\n",
            "ko-KR-InJoonNeural - Male\n",
            "ko-KR-SunHiNeural - Female\n",
            "lo-LA-ChanthavongNeural - Male\n",
            "lo-LA-KeomanyNeural - Female\n",
            "lv-LV-EveritaNeural - Female\n",
            "lv-LV-NilsNeural - Male\n",
            "lt-LT-LeonasNeural - Male\n",
            "lt-LT-OnaNeural - Female\n",
            "mk-MK-AleksandarNeural - Male\n",
            "mk-MK-MarijaNeural - Female\n",
            "ms-MY-OsmanNeural - Male\n",
            "ms-MY-YasminNeural - Female\n",
            "ml-IN-MidhunNeural - Male\n",
            "ml-IN-SobhanaNeural - Female\n",
            "mt-MT-GraceNeural - Female\n",
            "mt-MT-JosephNeural - Male\n",
            "mr-IN-AarohiNeural - Female\n",
            "mr-IN-ManoharNeural - Male\n",
            "mn-MN-BataaNeural - Male\n",
            "mn-MN-YesuiNeural - Female\n",
            "ne-NP-HemkalaNeural - Female\n",
            "ne-NP-SagarNeural - Male\n",
            "nb-NO-FinnNeural - Male\n",
            "nb-NO-PernilleNeural - Female\n",
            "ps-AF-GulNawazNeural - Male\n",
            "ps-AF-LatifaNeural - Female\n",
            "fa-IR-DilaraNeural - Female\n",
            "fa-IR-FaridNeural - Male\n",
            "pl-PL-MarekNeural - Male\n",
            "pl-PL-ZofiaNeural - Female\n",
            "pt-BR-ThalitaMultilingualNeural - Female\n",
            "pt-BR-AntonioNeural - Male\n",
            "pt-BR-FranciscaNeural - Female\n",
            "pt-PT-DuarteNeural - Male\n",
            "pt-PT-RaquelNeural - Female\n",
            "ro-RO-AlinaNeural - Female\n",
            "ro-RO-EmilNeural - Male\n",
            "ru-RU-DmitryNeural - Male\n",
            "ru-RU-SvetlanaNeural - Female\n",
            "sr-RS-NicholasNeural - Male\n",
            "sr-RS-SophieNeural - Female\n",
            "si-LK-SameeraNeural - Male\n",
            "si-LK-ThiliniNeural - Female\n",
            "sk-SK-LukasNeural - Male\n",
            "sk-SK-ViktoriaNeural - Female\n",
            "sl-SI-PetraNeural - Female\n",
            "sl-SI-RokNeural - Male\n",
            "so-SO-MuuseNeural - Male\n",
            "so-SO-UbaxNeural - Female\n",
            "es-AR-ElenaNeural - Female\n",
            "es-AR-TomasNeural - Male\n",
            "es-BO-MarceloNeural - Male\n",
            "es-BO-SofiaNeural - Female\n",
            "es-CL-CatalinaNeural - Female\n",
            "es-CL-LorenzoNeural - Male\n",
            "es-CO-GonzaloNeural - Male\n",
            "es-CO-SalomeNeural - Female\n",
            "es-ES-XimenaNeural - Female\n",
            "es-CR-JuanNeural - Male\n",
            "es-CR-MariaNeural - Female\n",
            "es-CU-BelkysNeural - Female\n",
            "es-CU-ManuelNeural - Male\n",
            "es-DO-EmilioNeural - Male\n",
            "es-DO-RamonaNeural - Female\n",
            "es-EC-AndreaNeural - Female\n",
            "es-EC-LuisNeural - Male\n",
            "es-SV-LorenaNeural - Female\n",
            "es-SV-RodrigoNeural - Male\n",
            "es-GQ-JavierNeural - Male\n",
            "es-GQ-TeresaNeural - Female\n",
            "es-GT-AndresNeural - Male\n",
            "es-GT-MartaNeural - Female\n",
            "es-HN-CarlosNeural - Male\n",
            "es-HN-KarlaNeural - Female\n",
            "es-MX-DaliaNeural - Female\n",
            "es-MX-JorgeNeural - Male\n",
            "es-NI-FedericoNeural - Male\n",
            "es-NI-YolandaNeural - Female\n",
            "es-PA-MargaritaNeural - Female\n",
            "es-PA-RobertoNeural - Male\n",
            "es-PY-MarioNeural - Male\n",
            "es-PY-TaniaNeural - Female\n",
            "es-PE-AlexNeural - Male\n",
            "es-PE-CamilaNeural - Female\n",
            "es-PR-KarinaNeural - Female\n",
            "es-PR-VictorNeural - Male\n",
            "es-ES-AlvaroNeural - Male\n",
            "es-ES-ElviraNeural - Female\n",
            "es-US-AlonsoNeural - Male\n",
            "es-US-PalomaNeural - Female\n",
            "es-UY-MateoNeural - Male\n",
            "es-UY-ValentinaNeural - Female\n",
            "es-VE-PaolaNeural - Female\n",
            "es-VE-SebastianNeural - Male\n",
            "su-ID-JajangNeural - Male\n",
            "su-ID-TutiNeural - Female\n",
            "sw-KE-RafikiNeural - Male\n",
            "sw-KE-ZuriNeural - Female\n",
            "sw-TZ-DaudiNeural - Male\n",
            "sw-TZ-RehemaNeural - Female\n",
            "sv-SE-MattiasNeural - Male\n",
            "sv-SE-SofieNeural - Female\n",
            "ta-IN-PallaviNeural - Female\n",
            "ta-IN-ValluvarNeural - Male\n",
            "ta-MY-KaniNeural - Female\n",
            "ta-MY-SuryaNeural - Male\n",
            "ta-SG-AnbuNeural - Male\n",
            "ta-SG-VenbaNeural - Female\n",
            "ta-LK-KumarNeural - Male\n",
            "ta-LK-SaranyaNeural - Female\n",
            "te-IN-MohanNeural - Male\n",
            "te-IN-ShrutiNeural - Female\n",
            "th-TH-NiwatNeural - Male\n",
            "th-TH-PremwadeeNeural - Female\n",
            "tr-TR-EmelNeural - Female\n",
            "tr-TR-AhmetNeural - Male\n",
            "uk-UA-OstapNeural - Male\n",
            "uk-UA-PolinaNeural - Female\n",
            "ur-IN-GulNeural - Female\n",
            "ur-IN-SalmanNeural - Male\n",
            "ur-PK-AsadNeural - Male\n",
            "ur-PK-UzmaNeural - Female\n",
            "uz-UZ-MadinaNeural - Female\n",
            "uz-UZ-SardorNeural - Male\n",
            "vi-VN-HoaiMyNeural - Female\n",
            "vi-VN-NamMinhNeural - Male\n",
            "cy-GB-AledNeural - Male\n",
            "cy-GB-NiaNeural - Female\n",
            "zu-ZA-ThandoNeural - Female\n",
            "zu-ZA-ThembaNeural - Male\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Voice change ki hai or code ko fast kiya hai\n",
        "import os\n",
        "import re\n",
        "import edge_tts\n",
        "import asyncio\n",
        "import moviepy.editor as mp\n",
        "from pptx import Presentation\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "# === Step 1: Convert PPT to PDF and Extract Images ===\n",
        "ppt_file = \"/content/OOP_Introduction_Python.pptx\"\n",
        "pdf_file = \"/content/OOP_Introduction_Python.pdf\"\n",
        "output_folder = \"output\"\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Convert PPTX to PDF using LibreOffice (Linux)\n",
        "os.system(f'soffice --headless --convert-to pdf \"{ppt_file}\" --outdir \"/content\"')\n",
        "\n",
        "# Convert PDF pages to images (each slide as an image)\n",
        "slides = convert_from_path(pdf_file, dpi=300)  # High-quality images\n",
        "image_files = []\n",
        "for i, slide in enumerate(slides):\n",
        "    image_path = f\"{output_folder}/slide_{i+1}.png\"\n",
        "    slide.save(image_path, \"PNG\")\n",
        "    image_files.append(image_path)\n",
        "\n",
        "# === Step 2: Generate Audio for Each Slide (Male Voice) ===\n",
        "def clean_text(text):\n",
        "    \"\"\" Remove unwanted symbols from text. \"\"\"\n",
        "    text = re.sub(r'[_\"#*<>@{}[\\]()/\\\\]', '', text)  # Remove unwanted symbols\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "async def generate_audio(text, output_file):\n",
        "    \"\"\" Convert text to speech using Edge TTS (Microsoft AI). \"\"\"\n",
        "    voice = \"en-GB-Wavenet-B\"  # Male Voice\n",
        "    tts = edge_tts.Communicate(text, voice, rate=\"+10%\")  # Slightly faster\n",
        "    await tts.save(output_file)\n",
        "\n",
        "audio_files = []\n",
        "for i, img_path in enumerate(image_files):\n",
        "    slide_text = input(f\"Enter narration text for Slide {i+1}: \")\n",
        "    slide_text = clean_text(slide_text)\n",
        "\n",
        "    audio_path = f\"{output_folder}/slide_{i+1}.mp3\"\n",
        "    asyncio.run(generate_audio(slide_text, audio_path))\n",
        "\n",
        "    audio_files.append(audio_path)\n",
        "\n",
        "# === Step 3: Create Video (High-Quality, GPU Optimized) ===\n",
        "video_clips = []\n",
        "for img_path, audio_path in zip(image_files, audio_files):\n",
        "    audio_clip = mp.AudioFileClip(audio_path)\n",
        "    image_clip = mp.ImageClip(img_path).set_duration(audio_clip.duration)\n",
        "    video_clips.append(image_clip.set_audio(audio_clip))\n",
        "\n",
        "# Combine all clips\n",
        "final_video = mp.concatenate_videoclips(video_clips, method=\"compose\")\n",
        "\n",
        "# Save final video (High Quality + GPU Acceleration)\n",
        "video_output_path = \"final_presentation.mp4\"\n",
        "final_video.write_videofile(video_output_path, codec=\"h264_nvenc\", threads=8, preset=\"ultrafast\", fps=30)\n",
        "\n",
        "print(f\"🎥 Video created successfully: {video_output_path}\")\n"
      ],
      "metadata": {
        "id": "EyAAiJFx3LfQ",
        "outputId": "780ff880-7b4d-410a-ee31-9e27d24d8732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter narration text for Slide 1:  \"Hello everyone! Welcome to this session on Object-Oriented Programming (OOP) in Python. Today, we will dive into the fundamental concepts of OOP, why it is important, and how we can use it effectively in Python. Whether you are a beginner or someone looking to refine your knowledge, this session will help you get a clear understanding of OOP. So, let’s begin!\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid voice 'en-GB-Wavenet-B'.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-6f509c6f23fd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0maudio_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{output_folder}/slide_{i+1}.mp3\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslide_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0maudio_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 raise RuntimeError(\n\u001b[1;32m     97\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-6f509c6f23fd>\u001b[0m in \u001b[0;36mgenerate_audio\u001b[0;34m(text, output_file)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m\"\"\" Convert text to speech using Edge TTS (Microsoft AI). \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mvoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"en-GB-Wavenet-B\"\u001b[0m  \u001b[0;31m# Male Voice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mtts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_tts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"+10%\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Slightly faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mawait\u001b[0m \u001b[0mtts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/edge_tts/communicate.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, text, voice, rate, volume, pitch, connector, proxy, connect_timeout, receive_timeout)\u001b[0m\n\u001b[1;32m    252\u001b[0m     ):\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# Validate TTS settings and store the TTSConfig object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtts_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTTSConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpitch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# Validate the text parameter.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/edge_tts/data_classes.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, voice, rate, volume, pitch)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/edge_tts/data_classes.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Validate the rate, volume, and pitch parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         self.validate_string_param(\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;34m\"voice\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/edge_tts/data_classes.py\u001b[0m in \u001b[0;36mvalidate_string_param\u001b[0;34m(param_name, param_value, pattern)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{param_name} must be str\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_value\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid {param_name} '{param_value}'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparam_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid voice 'en-GB-Wavenet-B'."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JihSRIax3LeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L_Fi9C_Y3LaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hnZ6lsKR3LZM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7JaGY7pvUF8sfEMR1vjWf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}