{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDuLM8lbpCJZ4Ek7iQ1kPE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bharatgaur/Projects/blob/main/Text%20PPT%20to%20Video%20creation1.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generating video very fine base code\n",
        "!pip install edge-tts moviepy pdf2image\n",
        "!apt-get install -y poppler-utils\n",
        "import edge_tts\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "from moviepy.editor import *\n",
        "from pdf2image import convert_from_path\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Fix asyncio issue in Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# PDF file path\n",
        "pdf_file = \"/content/AI-Powered Tutor.pdf\"\n",
        "\n",
        "# Convert PDF to images\n",
        "images = convert_from_path(pdf_file)\n",
        "\n",
        "# Get text input for each page\n",
        "page_texts = []\n",
        "for i in range(len(images)):\n",
        "    text = input(f\"Enter text for page {i+1}: \")\n",
        "    page_texts.append(text)\n",
        "\n",
        "# Function to convert text to speech\n",
        "async def text_to_speech(text, audio_file):\n",
        "    voice = \"en-GB-RyanNeural\"  # British Male Voice\n",
        "    tts = edge_tts.Communicate(text, voice)\n",
        "    await tts.save(audio_file)\n",
        "\n",
        "# Generate video for each page\n",
        "clips = []\n",
        "for i, (image, text) in enumerate(zip(images, page_texts)):\n",
        "    audio_file = f\"audio_{i}.mp3\"\n",
        "    video_file = f\"video_{i}.mp4\"\n",
        "\n",
        "    # Convert text to speech\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(text_to_speech(text, audio_file))\n",
        "\n",
        "    # Load audio file\n",
        "    audio = AudioFileClip(audio_file)\n",
        "    duration = audio.duration\n",
        "\n",
        "    # Convert PIL image to NumPy array\n",
        "    image_np = np.array(image)\n",
        "\n",
        "    # Save image as video background\n",
        "    img_clip = ImageClip(image_np)\n",
        "    img_clip = img_clip.set_duration(duration).resize((1280, 720))\n",
        "\n",
        "    # Combine video & audio\n",
        "    final_clip = img_clip.set_audio(audio)\n",
        "    clips.append(final_clip)\n",
        "\n",
        "# Concatenate all video clips\n",
        "final_video = concatenate_videoclips(clips, method=\"compose\")\n",
        "final_video.write_videofile(\"final_presentation.mp4\", fps=30, codec=\"libx264\", threads=4, preset=\"ultrafast\")\n",
        "\n",
        "# Download final video\n",
        "from google.colab import files\n",
        "files.download(\"final_presentation.mp4\")"
      ],
      "metadata": {
        "id": "xCaBS9O1fq-Y",
        "outputId": "14f526a2-66b4-4b08-8ab5-02545bd04f66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting edge-tts\n",
            "  Downloading edge_tts-7.0.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (3.11.13)\n",
            "Requirement already satisfied: certifi>=2023.11.17 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (2025.1.31)\n",
            "Collecting srt<4.0.0,>=3.4.1 (from edge-tts)\n",
            "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate<1.0.0,>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (4.12.2)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.1.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (25.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Downloading edge_tts-7.0.0-py3-none-any.whl (23 kB)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: srt\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22428 sha256=2b2fa30ca6fb002857498c52ac2b7764f607eb421b27afe11c1d1c05dcfb217d\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/43/f1/23ee9119497fcb57d9f7046fbf34c6d9027c46a1fa7824cf08\n",
            "Successfully built srt\n",
            "Installing collected packages: srt, pdf2image, edge-tts\n",
            "Successfully installed edge-tts-7.0.0 pdf2image-1.17.0 srt-3.5.3\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.6 [186 kB]\n",
            "Fetched 186 kB in 1s (225 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 125044 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.6_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter text for page 1: AI-Powered Tutor Revolutionizing Education with AI Education is undergoing a significant transformation, with AI at the forefront of this change. Traditional learning models often fail to provide personalized and engaging experiences for students. Our AI-powered tutor bridges this gap by offering customized, interactive learning. This presents a lucrative investment opportunity, as AI-driven education is not just the future—it is the present.\n",
            "Enter text for page 2: Explosive Market Growth in EdTech The EdTech industry is witnessing rapid expansion, with AI playing a crucial role. Globally, the AI in education market is forecasted to reach $25 billion by 2030, growing at an impressive 45% CAGR. India, a booming market, has experienced a post-pandemic surge in EdTech adoption, with projections exceeding $30 billion by 2027. These figures highlight the immense potential for AI-driven learning solutions.\n",
            "Enter text for page 3: Target Audience: Lifelong Learners Our AI tutor caters to a broad spectrum of learners: Students: K-12 and higher education students can benefit from concept-based, interactive learning, improving retention and understanding. Exam Aspirants: Competitive exams like JEE, NEET, and UPSC require rigorous preparation. AI-driven insights and personalized learning paths enhance efficiency and success rates. Professionals: Continuous skill development is crucial in today’s job market. Our platform offers tailored courses for upskilling and career growth. This diversified target audience ensures a broad market reach and sustained demand.\n",
            "Enter text for page 4: Solving Key Pain Points in Education Despite technological advancements, education still faces major challenges: Lack of Personalization – Traditional classroom methods do not adapt to individual learning styles. AI-driven education tailors content to each learner’s needs. Limited Accessibility – Quality education remains expensive and out of reach for many. AI tutoring provides a cost-effective alternative. Low Engagement – Static, text-heavy content often leads to disinterest. AI introduces interactive storytelling and gamification, making learning engaging and effective. By addressing these core issues, our AI tutor revolutionizes the learning experience.\n",
            "Enter text for page 5: Our Solution: An AI-Powered Tutor Our AI tutor is designed to enhance learning through advanced technology: Interactive: Real-world scenarios and AI-driven explanations make concepts relatable. Engaging: Animated storytelling simplifies complex subjects, improving comprehension. Adaptive: AI continuously tracks progress and adjusts learning paths for optimal results. Scalable: The solution is accessible to millions, offering affordable and high-quality education. This innovation ensures that students receive a dynamic and efficient learning experience.\n",
            "Enter text for page 6: Business Model: Diverse Revenue Streams Our monetization strategy ensures sustainability and profitability through multiple revenue streams: Subscription Model: At ₹199/month, students receive unlimited AI tutoring, making it affordable and scalable. B2B Licensing: Schools and coaching centers can integrate our AI tutor into their curriculum, expanding reach. Freemium Model: Free basic content with premium AI-driven deep learning ensures wide accessibility while driving paid conversions. Corporate Training: AI-powered courses for professional development generate additional revenue. This diversified approach secures long-term financial stability while maximizing market penetration.\n",
            "Enter text for page 7: Funding & Expected ROI With a well-structured growth plan, our AI tutor is projected to onboard 1 million+ students within four years. This adoption rate is expected to generate annual revenue of ₹3-5 crore, ensuring a high return on investment (ROI). The rapidly expanding EdTech market and our scalable model make significant growth potential.\n",
            "Enter text for page 8: Conclusion & Call to Action The future of education is AI-powered, interactive, and accessible. Our AI tutor contributes to a mission that democratizes learning. We invite potential investors and partners to collaborate with us in transforming education for millions. Let’s make quality education available to everyone—contact us today to be part of this revolution!\n",
            "Moviepy - Building video final_presentation.mp4.\n",
            "MoviePy - Writing audio in final_presentationTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_presentation.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready final_presentation.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6b5abd7d-4b6f-4355-ab44-98eb6cb453de\", \"final_presentation.mp4\", 10448814)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "62Nop2aQfqqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QhBmnFqFfqm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "byyQjvqofqlk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}