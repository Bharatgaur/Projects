{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGNIb/9w43vQSR+Q6vlCuz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bharatgaur/Projects/blob/main/Text%20to%20speech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install edge-tts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-jF6Y__8iQ_",
        "outputId": "f88acac7-21eb-4db9-823b-a9f5cb052bcf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: edge-tts in /usr/local/lib/python3.11/dist-packages (7.0.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (3.11.12)\n",
            "Requirement already satisfied: certifi>=2023.11.17 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (2025.1.31)\n",
            "Requirement already satisfied: srt<4.0.0,>=3.4.1 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (3.5.3)\n",
            "Requirement already satisfied: tabulate<1.0.0,>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp<4.0.0,>=3.8.0->edge-tts) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import edge_tts\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "\n",
        "# Fix asyncio issue in Colab/Jupyter Notebook\n",
        "nest_asyncio.apply()\n",
        "\n",
        "async def generate_speech(text, file_name, voice=\"en-US-GuyNeural\"):\n",
        "    \"\"\"Given text and file_name, generates an MP3 file using Edge TTS.\"\"\"\n",
        "    tts = edge_tts.Communicate(text, voice)\n",
        "    await tts.save(file_name)\n",
        "    print(f\"MP3 file '{file_name}' has been generated successfully!\")\n",
        "\n",
        "def text_to_speech(file_name, text, voice=\"en-US-GuyNeural\"):\n",
        "    \"\"\"Wrapper function to run the async function in a synchronous way.\"\"\"\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(generate_speech(text, file_name, voice))\n",
        "\n",
        "# Example Usage\n",
        "text_to_speech(\"output.mp3\", \"Hello, this is an AI-generated voice!\")\n"
      ],
      "metadata": {
        "id": "kjGm5J1OA7EU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e69530b-a1f5-4975-8aa7-7b6fc3e5bb05"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MP3 file 'output.mp3' has been generated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = \"Self Assessment.mp3\""
      ],
      "metadata": {
        "id": "DZaMHQLI_sVi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Introduce Yourself - AlmaX\n",
        "\n",
        "Hello everyone, my name is Bharat Gaur, and I am a dedicated Data Scientist from Ghaziabad, Uttar Pradesh. My expertise lies in machine learning, statistical analysis, and extracting meaningful insights from complex datasets to drive data-driven decision-making.\n",
        "\n",
        "Academic Background:\n",
        "I have a strong educational foundation in Data Science and Artificial Intelligence. I completed my Master’s in Data Science & AI from IIT Guwahati (in collaboration with AlmaBetter). Before that, I pursued a Bachelor’s degree in Mechanical Engineering from Aligarh College of Engineering & Technology.\n",
        "\n",
        "Technical Skills:\n",
        "I have hands-on experience with multiple programming languages and tools essential for Data Science:\n",
        "\n",
        "Programming Languages: Python and SQL, along with libraries like NumPy and Pandas for data manipulation, and scikit-learn for machine learning.\n",
        "\n",
        "Data Analysis & Visualization Tools: I am skilled in Advanced Excel, Tableau, and Power BI, which help in creating insightful reports and dashboards.\n",
        "\n",
        "Specialized Frameworks: My expertise extends to advanced areas like Machine Learning, Artificial Intelligence, Natural Language Processing (NLP), Deep Learning,\n",
        "Computer Vision, and MLOps, enabling me to work on cutting-edge AI solutions.\n",
        "\n",
        "Professional Experience:\n",
        "I have diverse work experience across different industries, contributing to various aspects of data analysis, quality control, and supply chain optimization.\n",
        "Currently, I am working as a Data Analyst at Moozza Footwear LLP (since 2024), where I focus on optimizing inventory management and improving operational efficiency through data-driven strategies.\n",
        "Previously, I worked as a QA QC Engineer at ARC Infratech (2020–2024), ensuring quality compliance and process optimization.\n",
        "Before that, I was a Supply Chain Engineer at Shaurya Plastic Molding Works (2018–2020), where I played a key role in improving production logistics and streamlining operations.\n",
        "Certifications & Achievements:\n",
        "To further strengthen my expertise, I have earned multiple certifications and recognitions:\n",
        "Full Stack Data Science Certification (2023–2024) from AlmaBetter, which provided in-depth knowledge of data science concepts and practical applications.\n",
        "Gold Badges on HackerRank in SQL and Python, demonstrating my proficiency in problem-solving and technical skills.\n",
        "Hobbies & Interests:\n",
        "Beyond my professional work, I am passionate about exploring advancements in Artificial Intelligence, staying updated with the latest industry trends, and engaging in fitness and sports to maintain an active lifestyle.\n",
        "This was a brief introduction about me. Thank you for listening!\n",
        "\n",
        "\n",
        "AlmaBetter Project Explanation\n",
        "Hello, today I am going to explain a project I worked on at AlmaBetter. The objective of this project was to predict the daily demand for bike-sharing services in Seoul by analyzing historical data and various environmental factors. The goal was to ensure that bikes were available when and where people needed them, allocate resources efficiently, and ultimately enhance user satisfaction.\n",
        "Approach We Followed:\n",
        "1. Data Preparation:\n",
        "To build an effective prediction model, we first analyzed different factors that could impact bike demand. These included:\n",
        "Weather conditions such as temperature, humidity, and rainfall.\n",
        "Public holidays, as demand fluctuates on special days.\n",
        "Timestamps, including the time of day and whether it was a weekday or weekend.\n",
        "Since real-world data is often incomplete, we addressed missing values using various imputation techniques. We also created new features, such as:\n",
        "Differentiating between weekdays and weekends.\n",
        "Grouping time periods (morning, afternoon, evening, and night).\n",
        "Identifying seasonal trends to capture demand patterns more effectively.\n",
        "2. Tools & Techniques Used:\n",
        "For this project, we worked with powerful tools and libraries to analyze data and build machine learning models.\n",
        "Tools: We used Python for coding and Google Colab for running our experiments.\n",
        "Libraries: Our analysis and visualization were done using Pandas, Scikit-learn, Matplotlib, Seaborn, and NumPy.\n",
        "Models: We tested multiple machine learning models and found that Random Forest and Gradient Boosting Regressor performed well. To get the best results, we fine-tuned these models using GridSearchCV.\n",
        "Challenges Faced & Solutions Implemented:\n",
        "Every project comes with challenges, and here’s how we tackled them:\n",
        "Missing Data: Some data points were missing, so we filled them using mean median imputation and forward fill techniques to maintain accuracy.\n",
        "Overfitting: To avoid our model from learning noise instead of patterns, we used ensemble models like Random Forest and Gradient Boosting, which generalize better.\n",
        "Data Imbalance: The demand for bikes varied significantly at different times of the day. To ensure our model was fair, we applied normalization techniques to balance the data.\n",
        "Project Outcomes:\n",
        "Best Performing Model: After testing multiple models, we found that Gradient Boosting Regressor had the lowest Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE), meaning it provided the most accurate predictions.\n",
        "Key Insights: Our analysis showed that weather conditions, time of day, and holidays had a major impact on bike demand.\n",
        "Business Impact:\n",
        "The insights from this project can significantly improve the bike-sharing system in several ways:\n",
        "Better Resource Allocation: Authorities can distribute bikes more effectively, reducing shortages or excess supply.\n",
        "Improved User Experience: Riders experience shorter wait times, leading to higher customer satisfaction.\n",
        "Cost Optimization: Optimizing bike availability helps reduce operational costs and improves overall efficiency.\n",
        "Conclusion:\n",
        "This project demonstrates how data-driven models can revolutionize urban mobility by making bike-sharing services more efficient. By leveraging machine learning and predictive analytics, we can contribute to smart transportation solutions and improve the way people commute in cities.\n",
        "Thank you for listening!\n",
        "\n",
        "\n",
        "Dealing Failures\n",
        "We often learn a great deal from our failures. Could you describe a time when you failed and what you learned from the experience?\n",
        "Failure is something we all experience at different points in life. While it can be difficult and discouraging, it is also one of the greatest teachers. Every time we fail, we get an opportunity to learn, grow, and improve.\n",
        "How we respond to failure plays a huge role in shaping our future. Instead of seeing it as the end of the road, we should treat it as a lesson that helps us move forward. The most important thing is to acknowledge our feelings, accept the situation, and reflect on what went wrong. Once we understand the reasons behind the failure, we can use that knowledge to make better decisions in the future.\n",
        "Another important step is reframing the way we see failure. Instead of considering it a setback, we should view it as an opportunity for growth. Many successful people have failed multiple times before achieving success. What sets them apart is their resilience—their ability to learn from mistakes and keep pushing forward.\n",
        "Seeking support from mentors, friends, or colleagues can also make a big difference. Sometimes, a fresh perspective or encouragement from others can help us regain confidence and find a new approach to the problem.\n",
        "The key to overcoming failure is taking action again with a renewed mindset. Every failure brings us one step closer to success, as long as we don’t give up. Instead of avoiding failure, we should embrace it as an essential part of growth.\n",
        "Remember, the most successful people in the world are not those who never fail, but those who fail, learn, adapt, and keep moving forward with determination and hope.\n",
        "\n",
        "\n",
        "Parental Expectations\n",
        "Write about a time when you did not meet your or your parent’s expectations. Tell what happened and how you tried to fix the situations.\n",
        "Can you share a time when you fell short of your own parent’s expectations what happened and what did you do to address the situations please describe the steps you took to try and resolve the issues.\n",
        "\n",
        "Parental expectations play a big role in shaping a child's development. They influence how we approach education, career choices, and even our personal growth. When these expectations are positive and realistic, they can motivate us to do better, build confidence, and help us set meaningful goals. Parents who offer emotional support and encouragement create an environment where children feel safe to explore their interests and work toward their dreams.\n",
        "However, sometimes expectations can become overwhelming, especially when they are too rigid or unrealistic. This pressure may lead to stress, burnout, fear of failure, or even a strained relationship between parents and children. It’s important to find a balance—where expectations motivate rather than burden.\n",
        "A good way to handle this is through open communication. When parents and children have honest conversations, they can better understand each other’s perspectives. Setting realistic goals based on individual strengths and interests helps reduce pressure and makes achievements more fulfilling. Parents should also allow flexibility, adapting their expectations as children grow and discover new passions.\n",
        "At the heart of it all, unconditional support matters the most. When children know they are valued beyond their achievements, they feel more confident to take risks, learn from failures, and pursue what truly excites them. A balanced approach to parental expectations empowers children to reach their full potential while maintaining a healthy and supportive relationship with their parents.\n",
        "\n",
        "\n",
        "Pressure at Work or School College\n",
        "\n",
        "Feeling pressure at work, school, or college is something that most people experience. Deadlines, responsibilities, and expectations can sometimes feel overwhelming. However, managing this pressure in the right way is important for maintaining both mental well-being and good performance.\n",
        "Here are some effective ways to handle pressure:\n",
        "Time Management: Organizing tasks properly can reduce stress. Prioritizing important work, using planners or to-do lists, and avoiding procrastination can help keep things under control.\n",
        "\n",
        "\n",
        "Set Realistic Expectations: It’s important to know your limits. Instead of trying to do everything at once, break large projects into smaller, more manageable steps. This makes the work feel less overwhelming and helps maintain steady progress.\n",
        "\n",
        "\n",
        "Manage Stress Effectively: Taking breaks, engaging in physical activities like exercise, and practicing mindfulness or deep breathing can help in reducing stress and keeping a calm mindset.\n",
        "\n",
        "\n",
        "Seek Support: When things get overwhelming, talking to a trusted friend, teacher, mentor, or professional can provide relief and guidance. Having a strong support system can make challenges easier to handle.\n",
        "\n",
        "\n",
        "Maintain Healthy Habits: A balanced lifestyle, including proper sleep, a healthy diet, and setting personal boundaries, helps prevent burnout and keeps the mind and body energized.\n",
        "\n",
        "\n",
        "Stay Positive: Instead of focusing on what’s stressful, focus on progress. Staying in the present moment and visualizing success can keep you motivated.\n",
        "\n",
        "\n",
        "Recognize Your Limits: It’s okay to take a break when needed. Disconnecting from work or studies for a while can refresh your mind and improve focus when you return.\n",
        "\n",
        "\n",
        "Develop Problem-Solving Skills: When facing challenges, breaking them into smaller, manageable steps and focusing on what can be controlled can make them less stressful.\n",
        "\n",
        "\n",
        "Seek Professional Guidance: If the pressure feels too heavy to handle alone, seeking mentorship or counseling can help in learning better coping strategies.\n",
        "\n",
        "\n",
        "By following these approaches, work and study pressure can be managed effectively. Instead of letting stress hold you back, use it as an opportunity to grow, build resilience, and develop a strong mindset.\n",
        "\n",
        "\n",
        "Situation Handling\n",
        "\n",
        "On June 26, 2024, I faced a significant loss of ₹71,000 in options trading. The main reason behind this loss was overtrading—placing too many trades without proper analysis.\n",
        "The day started with high expectations, and I was actively involved in multiple trades. However, instead of following a structured plan, I made impulsive decisions. I took large positions without fully understanding market conditions. This lack of discipline, combined with poor risk management, led to a heavy financial loss.\n",
        "By the end of the day, I had a realization—successful trading is not just about making profits but also about managing risks effectively. This experience taught me an important lesson:\n",
        "Avoid Overtrading: Placing too many trades without a clear plan can be dangerous. It is essential to stick to a well-defined strategy.\n",
        "Control Emotions: The stock market is highly volatile. Making decisions based on fear or excitement can lead to losses. Staying calm and rational is crucial.\n",
        "Follow Risk Management: Setting stop-loss limits and managing position sizes can help protect capital and minimize risks.\n",
        "Take Breaks: Trading for long hours without breaks can lead to fatigue and poor decision-making. Stepping away from the screen helps maintain clarity and focus.\n",
        "This incident reinforced the importance of patience, discipline, and strategic planning in trading. Instead of rushing into trades, I now focus on analyzing the market carefully and making calculated decisions. Every failure is a learning opportunity, and this experience has made me a more cautious and disciplined trader.\n",
        "\n",
        "\n",
        "\n",
        "Difficult Choices\n",
        "\n",
        "In life, we all face difficult choices that can have a big impact on our future. These decisions often involve weighing different options, understanding consequences, and making the best possible choice based on the situation.\n",
        "A difficult choice could be related to career, education, relationships, or personal growth. For example, choosing between a stable job and a new opportunity, deciding whether to move to a new city for better prospects, or even making a tough call about ending something that no longer serves us.\n",
        "When faced with such choices, it’s important to:\n",
        "Analyze the situation carefully – Understand the pros and cons of each option.\n",
        "Think long-term – Consider how the decision will impact your future, not just the present moment.\n",
        "Seek advice if needed – Talking to mentors, family, or friends can give new perspectives.\n",
        "Trust yourself – Sometimes, logic alone isn’t enough. Listening to your intuition also plays a key role.\n",
        "Making difficult choices is never easy, but every decision teaches us something valuable. Even if things don’t go as planned, we learn, adapt, and grow stronger. The key is to make informed decisions and move forward with confidence.\n",
        "\n",
        "\n",
        "Own Goal\n",
        "\n",
        "During my academic journey at AlmaBetter, I set a clear goal: to master Python for data science and machine learning. I knew that learning Python would be crucial for building a strong career in this field. To achieve this, I followed a structured approach and stayed committed to my learning process.\n",
        "Steps I Took to Achieve This Goal:\n",
        "Breaking the Goal into Smaller Steps:\n",
        "\n",
        "\n",
        "I started with the basics of Python, ensuring I had a strong foundation.\n",
        "Gradually, I moved on to advanced topics like machine learning.\n",
        "Instead of rushing, I took a step-by-step approach to ensure a deeper understanding.\n",
        "Practicing Consistently:\n",
        "\n",
        "\n",
        "I worked on daily coding challenges to improve my problem-solving skills.\n",
        "I applied my learning to real-world datasets, which helped me gain hands-on experience.\n",
        "I actively sought feedback from peers and participated in coding communities to learn from others.\n",
        "How I Stayed Focused:\n",
        "I set achievable milestones, which kept me motivated and gave me a sense of progress.\n",
        "I used time management techniques like the Pomodoro method, which helped me stay productive without feeling overwhelmed.\n",
        "To keep myself motivated, I rewarded myself after completing projects and achieving small wins.\n",
        "Challenges I Faced and How I Overcame Them:\n",
        "Some machine learning concepts were initially difficult to grasp, but I tackled them through extensive research and consistent practice.\n",
        "Despite time constraints, I created a structured study schedule, ensuring that I dedicated enough time to learning.\n",
        "At times, self-doubt crept in, but instead of comparing myself with others, I focused on personal growth and progress.\n",
        "Through discipline, persistence, and effective learning strategies, I successfully mastered Python and developed a strong foundation in data science and machine learning. This journey not only strengthened my technical skills but also taught me the importance of patience and continuous learning.\n",
        "\n",
        "Effective Teacher\n",
        "\n",
        "An effective teacher plays a crucial role in shaping students' academic success and personal growth. A great teacher not only imparts knowledge but also inspires and supports students in their learning journey. Here are some key qualities that define an effective teacher:\n",
        "Strong Subject Knowledge:\n",
        "A good teacher has a deep understanding of the subject and can explain even complex concepts in a simple and clear manner. This helps students grasp difficult topics more easily.\n",
        "Effective Communication Skills:\n",
        "Communication is not just about speaking—it also includes listening and understanding students' needs. A teacher should present ideas in an engaging way and encourage open discussions so that students feel comfortable asking questions.\n",
        "Passion for Teaching:\n",
        "A passionate teacher can motivate and inspire students to develop an interest in learning. When a teacher enjoys teaching, it creates a positive and energetic atmosphere in the classroom.\n",
        "Empathy and Understanding:\n",
        "Every student learns at their own pace, and a good teacher recognizes this. Being empathetic means understanding students' academic and emotional struggles and providing the necessary support and encouragement.\n",
        "Patience and Flexibility:\n",
        "Different students have different learning styles. A great teacher remains patient and adapts teaching methods to ensure that every student understands the material effectively.\n",
        "Classroom Management Skills:\n",
        "An organized and well-managed classroom helps students stay focused. Setting clear rules and expectations creates a structured environment where students can learn efficiently.\n",
        "Adaptability:\n",
        "Learning methods are constantly evolving, and an effective teacher stays open to change. Whether using new teaching techniques or incorporating technology, adaptability ensures better learning experiences for students.\n",
        "Encouraging Critical Thinking:\n",
        "A great teacher does not just provide answers but encourages students to think independently and solve problems. This fosters creativity, curiosity, and confidence in students.\n",
        "Commitment to Continuous Learning:\n",
        "A teacher should always strive to improve their skills. By learning new techniques and staying updated with advancements in their field, they can offer students the best education possible.\n",
        "Building Positive Relationships with Students:\n",
        "Trust and mutual respect create a supportive learning environment. When students feel valued and understood, they are more motivated to learn and participate actively in class.\n",
        "By possessing these qualities, an effective teacher not only helps students achieve academic success but also nurtures their personal development, preparing them for future challenges with confidence and knowledge.\n",
        "\n",
        "\n",
        "Learning from Failure\n",
        "\n",
        "Learning from failure is an essential part of personal growth and success. Instead of seeing failure as a setback, we should treat it as an opportunity to improve and move forward. Here are some important ways to learn effectively from failure:\n",
        "1. Change Your Perspective:\n",
        "Failure is not the end of the road—it is simply a lesson in disguise. By adopting a growth mindset, we can see failures as temporary challenges rather than personal shortcomings. This mindset helps us stay positive and focused on learning from mistakes.\n",
        "2. Analyze What Went Wrong:\n",
        "It is important to take time to reflect on the situation and identify what led to the failure. Understanding the root cause helps us avoid repeating the same mistakes and allows us to make better decisions in the future.\n",
        "3. Make Necessary Adjustments:\n",
        "Once we know what went wrong, we should use that knowledge to adjust our approach. By improving strategies and making small changes, we can increase our chances of success in the next attempt.\n",
        "4. Stay Resilient and Keep Trying:\n",
        "Failure can be discouraging, but persistence is key. Emotional resilience helps us stay strong and keep moving forward, even when things don’t go as planned. Success comes to those who don’t give up, but instead, learn and grow from each challenge.\n",
        "5. Learn from Others:\n",
        "We don’t always have to learn from our own failures—sometimes, we can learn from the experiences of mentors, peers, and successful people who have overcome failures in their journeys. Seeking feedback and guidance helps us grow faster and avoid unnecessary mistakes.\n",
        "6. Build Confidence Through Small Wins:\n",
        "Failure can sometimes shake our confidence, but it is important to focus on progress rather than perfection. Celebrating small victories along the way helps boost self-confidence and keeps us motivated to keep going.\n",
        "7. Embrace the Process of Growth:\n",
        "Success is not about avoiding failure—it is about learning from it and using it as a stepping stone toward improvement. Every mistake teaches us something valuable, and each failure brings us one step closer to success.\n",
        "By embracing failure and learning from it, we can turn setbacks into valuable opportunities for growth. Failure is not a sign of weakness; rather, it is an essential part of the journey to achieving our goals.\n",
        "\n",
        "Favorite Movie  write about it\n",
        "\n",
        "One of my favorite movies is Bhool Bhulaiyaa (2007), a Bollywood film that beautifully blends psychological thriller and comedy. This unique combination makes the movie highly engaging and entertaining.\n",
        "Storyline:\n",
        "The movie follows a newlywed couple who move into an ancestral palace, which is believed to be haunted. As strange and mysterious events start happening, fear spreads among the residents. To uncover the truth, they seek help from Dr. Aditya Shrivastava (played by Akshay Kumar), a psychiatrist who takes on the challenge of solving the mystery.\n",
        "Key Highlights:\n",
        "Akshay Kumar’s Performance:\n",
        " Akshay Kumar’s portrayal of Dr. Aditya is both hilarious and intelligent. His comedic timing and charm add light-heartedness to the suspenseful plot. One of his most iconic moments is his interaction with Manjulika, a character central to the mystery.\n",
        "\n",
        "\n",
        "Vidya Balan’s Acting:\n",
        " Vidya Balan delivers a powerful performance, especially in the climax, where her acting leaves a lasting impact on the audience. She plays a key role in the mystery, making her character unforgettable.\n",
        "\n",
        "\n",
        "A Unique Blend of Genres:\n",
        " The film perfectly balances humor with suspense, keeping the audience both entertained and intrigued. It switches between comedy, thrill, and psychological depth, making it a rare cinematic experience.\n",
        "\n",
        "\n",
        "Memorable Music:\n",
        " The soundtrack of Bhool Bhulaiyaa is another highlight. Songs like \"Ami Je Tomar\" and \"Hare Krishna Hare Ram\" are deeply impactful and enhance the movie’s eerie yet engaging atmosphere.\n",
        "\n",
        "\n",
        "Cultural and Psychological Themes:\n",
        " The movie explores superstitions, mental health, and the clash between tradition and modern thinking. It presents a thought-provoking perspective on how beliefs shape people’s perceptions and decisions.\n",
        "\n",
        "\n",
        "Why You Should Watch It:\n",
        "It offers a perfect mix of suspense and comedy, making it a fun and thrilling watch.\n",
        "The performances by Akshay Kumar, Vidya Balan, and the supporting cast are outstanding.\n",
        "The story, music, and cinematography keep viewers engaged from start to finish.\n",
        "It provides an insight into cultural traditions while addressing modern issues like mental health.\n",
        "Overall, Bhool Bhulaiyaa is not just a movie—it is an experience. Whether you enjoy thrillers, comedies, or films with deep psychological elements, this movie has something for everyone!\n",
        "\n",
        "Typical Day\n",
        "\n",
        "On June 26, 2024, I faced a major financial loss of ₹71,000 in options trading. This loss happened mainly because of overtrading, which means making too many trades without proper planning.\n",
        "How the Day Started:\n",
        "I began the day with high hopes, expecting to make profitable trades. I was actively involved in multiple trades, hoping to maximize my earnings. However, in my excitement, I started making quick and impulsive decisions without properly analyzing the market trends.\n",
        "What Went Wrong:\n",
        "Instead of following a well-planned strategy, I took excessive positions, meaning I risked more money than I should have. I didn’t consider the market conditions carefully, and as a result, I made poor trading decisions. My lack of discipline and risk management led to huge losses by the end of the day.\n",
        "Lessons Learned:\n",
        "This experience taught me an important lesson about trading:\n",
        "Stick to a strategy: A planned approach helps avoid impulsive decisions.\n",
        "Control emotions: Emotional trading can lead to bad decisions, especially in a volatile market.\n",
        "Practice risk management: It’s important to set limits on how much to trade and not take unnecessary risks.\n",
        "Take breaks: Stepping away from trading at the right time helps in making clear and rational decisions.\n",
        "Although the loss was significant, it gave me a valuable lesson on patience, discipline, and smart risk management. Moving forward, I aim to be more cautious and strategic in my trading to avoid such mistakes in the future.\n",
        "\n",
        "Life Experience of Overcoming Challenges\n",
        "Write down how you have overcome challenges or obstacles in your academic or personal life. (You can talk about a specific experience in your life and steps you have taken to overcome the problems.)\n",
        "\n",
        "Facing and overcoming challenges has been an important part of my academic and personal growth. One of the most difficult yet transformative experiences in my journey was shifting from mechanical engineering to data science. Since my background was in engineering, I had very little experience with programming, data analysis, and machine learning. At first, this transition felt overwhelming, but I knew that with the right approach, I could succeed.\n",
        "Steps I Took to Overcome This Challenge:\n",
        "Focused Learning:\n",
        " To gain the required knowledge, I enrolled in a data science certification program. I made a structured learning plan and dedicated daily time to studying important concepts like Python, SQL, and machine learning. This step helped me build a strong foundation in data science.\n",
        "\n",
        "\n",
        "Hands-on Practice:\n",
        " Learning theory alone was not enough, so I focused on real-world projects. For example, I worked on analyzing hotel booking data to identify trends and created a model to predict bike-sharing demand. These projects helped me apply my learning practically and understand how data science is used in real-life scenarios.\n",
        "\n",
        "\n",
        "Staying Persistent:\n",
        " The learning process was not easy. There were times when I felt stuck or frustrated, but I reminded myself that every expert was once a beginner. Instead of giving up, I stayed motivated by setting small, achievable goals and celebrating progress. Whenever I faced difficulties, I sought help from mentors, peers, and online communities.\n",
        "\n",
        "\n",
        "Lessons Learned:\n",
        "Through this journey, I not only developed strong data science skills but also learned that persistence, continuous learning, and a positive mindset are key to overcoming challenges. This experience gave me the confidence to tackle new challenges and reinforced my belief that with dedication and effort, any obstacle can be overcome.\n",
        "\n",
        "\n",
        "Leadership Skills Demonstration\n",
        "Can you tell me about a time when you had to take charge and show leadership skills? This could be in school, college or at your workplace. Please feel free to provide an example to help illustrate your experience.\n",
        "\n",
        "Leadership skills are essential in both professional and personal life. One such experience where I had to take charge and demonstrate leadership was during my time as a QA QC Engineer at ARC Infratech.\n",
        "During a critical project, we faced major challenges due to repeated quality issues and missed deadlines. These problems were causing delays and affecting the overall progress of the project. I realized that if no immediate action was taken, the project could fail, leading to significant losses for the company.\n",
        "Steps I Took as a Leader:\n",
        "Identifying the Problem:\n",
        " The first step was to analyze the root causes of the issues. I organized a team meeting where we discussed the key challenges. Through this discussion, we identified that the main problems were lack of proper communication among team members and inefficient quality control processes.\n",
        "\n",
        "\n",
        "Implementing Solutions:\n",
        " To resolve these issues, I introduced a structured quality review system, which ensured that every process was carefully checked before moving forward. I also set up regular check-ins with all stakeholders to monitor progress and address concerns in real time.\n",
        "\n",
        "\n",
        "Assigning Clear Responsibilities:\n",
        " To improve efficiency, I made sure that every team member had clearly defined roles and responsibilities. This helped in avoiding confusion and ensured that everyone was accountable for their tasks.\n",
        "\n",
        "\n",
        "Mentoring and Guidance:\n",
        " Since some junior team members lacked experience, I took the initiative to mentor them and provide necessary guidance. I helped them improve their skills, which boosted their confidence and made them more effective in their roles.\n",
        "\n",
        "\n",
        "Results:\n",
        "Due to these efforts, the project was completed on time with significantly fewer quality issues. Additionally, the team became more organized, efficient, and motivated. This experience taught me that leadership is not just about giving orders, but about understanding problems, guiding the team, and ensuring collective success.\n",
        "\n",
        "\n",
        "Thinking on your feet\n",
        " Can you describe a situation when you had to make a quick decision without much time to think, and it had a positive outcome? Please share the details of the situation, what decision you made, and how it led to a positive result.\n",
        "\n",
        "There was a situation on June 26, 2024, when I had to make a quick decision under pressure while trading in the stock market. That day, I was actively engaged in options trading, expecting good profits. However, in my eagerness to maximize gains, I took multiple trades without fully analyzing the market conditions.\n",
        "The Challenge:\n",
        "I overtraded, taking excessive positions without a clear strategy.\n",
        "I did not properly manage risk, which led to a significant loss of ₹71,000 in just one day.\n",
        "My emotions took over, and instead of stopping, I kept trying to recover losses, making the situation worse.\n",
        "The Quick Decision:\n",
        "By the end of the day, I stepped back and realized that continuing to trade impulsively would only lead to further losses. I made a quick and firm decision to stop trading immediately and review what went wrong. This decision prevented me from making additional mistakes in a highly emotional state.\n",
        "The Positive Outcome:\n",
        "I learned a valuable lesson about risk management and the dangers of overtrading.\n",
        "I understood the importance of having a well-planned strategy instead of making impulsive decisions.\n",
        "I realized that trading requires discipline and patience, and controlling emotions is key to long-term success.\n",
        "From that day onward, I started following a structured trading plan, taking calculated risks, and avoiding emotional decisions.\n",
        "This experience transformed my approach to trading. It taught me that making quick, thoughtful decisions—like knowing when to stop and reassess—can prevent further damage and lead to long-term improvement.\n",
        "\n",
        "\n",
        "\n",
        "Successful Persuasion\n",
        "Write about a time when you successfully persuaded someone to see things your way\n",
        "\n",
        "There was a time when I successfully persuaded someone to see things from my perspective, and it was related to a valuable lesson I learned in options trading.\n",
        "On June 26, 2024, I faced a major loss of ₹71,000 in options trading. The day started with high expectations, and I was actively involved in multiple trades. However, in my eagerness to make profits, I kept taking excessive positions without fully analyzing the market conditions. I was trading impulsively, driven by emotions rather than logic. Unfortunately, this lack of discipline and proper risk management led to significant losses.\n",
        "After this experience, I took time to reflect on what went wrong. I realized that overtrading—constantly entering and exiting positions without a solid strategy—was my biggest mistake. I also understood that controlling emotions and following a structured trading plan are crucial for success in the stock market.\n",
        "Later, I had a conversation with a friend who was also getting into options trading. He was making the same mistakes—overtrading, ignoring risk management, and letting emotions drive his decisions. I shared my personal experience with him and explained how my losses taught me the importance of patience, discipline, and strategic trading.\n",
        "At first, he was reluctant to listen, as he believed that more trades meant more profit. But after I broke down my experience step by step and showed him how impulsive decisions lead to heavy losses, he started to understand. I also introduced him to risk management techniques, such as setting a stop-loss, using proper position sizing, and taking breaks to maintain clarity.\n",
        "By the end of our discussion, he agreed to adopt a more disciplined approach to trading. He started planning his trades carefully and avoided unnecessary risks. A few weeks later, he told me that he was able to protect his capital and make better trading decisions because of the lessons I shared.\n",
        "This experience taught me that persuasion is most effective when backed by real-life experiences. Instead of just giving advice, sharing personal failures and learnings can help others connect with the message and make better choices.\n",
        "\n",
        "\n",
        "Unexpected Problem\n",
        "Write about when an unexpected problem derailed your plan to archive a goal. How did you overcome and get back on track\n",
        "\n",
        "There was a time when I faced an unexpected problem that completely disrupted my goal. On June 26, 2024, I suffered a huge financial loss of ₹71,000 in options trading. This setback was mainly due to overtrading, which happened because of impulsiveness and poor risk management.\n",
        "How It Happened:\n",
        "That day, I started trading with high expectations, believing I could make good profits. As the market moved, I entered multiple trades without fully analyzing the market trends. I took excessive positions, hoping to maximize gains. However, instead of profits, I faced unexpected losses. Since I wasn’t following a structured strategy, my emotions took over, leading to further bad decisions.\n",
        "The Impact:\n",
        "By the end of the day, I realized how overtrading and emotional decisions led to this huge loss. It was a wake-up call that made me understand the importance of self-discipline in trading. I also recognized that I needed to manage risks better and avoid making decisions based on impulse.\n",
        "How I Overcame the Setback:\n",
        "Analyzed My Mistakes – I took time to review my trades, identifying where I went wrong.\n",
        "Developed a Stronger Strategy – I created a clear trading plan with proper risk management rules.\n",
        "Controlled Emotions – I practiced staying calm during market fluctuations instead of reacting impulsively.\n",
        "Took a Break – I stepped away from trading for a while to regain clarity and avoid further losses.\n",
        "Focused on Learning – I studied successful trading strategies and learned from experienced traders.\n",
        "Lesson Learned:\n",
        "This experience taught me that trading without discipline and a solid plan can lead to heavy losses. I realized the importance of patience, risk management, and emotional control. I also learned that taking short breaks in high-pressure situations helps in making better decisions.\n",
        "Now, I follow a structured approach, ensuring that every trade is based on analysis rather than emotions. This setback, though painful, ultimately made me a more disciplined and responsible trader.\n",
        "\n",
        "\n",
        "Good Habits\n",
        "Can you share one of your good habits that you believe can benefit others in terms of physical, emotional, or financial health? Why do you think this habit is essential, and how has it positively impacted your life? Please provide specific examples of how this habit has improved your well-being and what steps someone can take to incorporate it into their daily routine.\n",
        "One of the good habits that benefits physical, emotional, and financial health is time management. It helps me balance work, health, and personal life, reducing stress and improving productivity.\n",
        "Why is it essential?\n",
        "\n",
        "One of the best habits that has helped me improve my physical, emotional, and financial health is time management. When I manage my time well, I can balance my work, health, and personal life, which reduces stress and increases productivity.\n",
        "Why is Time Management Important?\n",
        "Time management is essential because it helps me prioritize important tasks, avoid unnecessary stress, and ensure that I have enough time for both work and personal activities, like exercise, relaxation, and self-improvement. When I plan my day properly, I don’t feel overwhelmed, and I can complete my tasks more efficiently.\n",
        "How Has It Helped Me?\n",
        "Physical Health: When I schedule time for regular exercise, I stay fit and feel more energetic throughout the day.\n",
        "Emotional Health: Managing time well reduces stress and allows me to engage in activities like meditation or hobbies that help me relax.\n",
        "Financial Health: With good time management, I can plan my finances better, track my expenses, and work towards my financial goals without last-minute worries.\n",
        "How Can You Incorporate Time Management in Your Life?\n",
        "Here are some simple steps to improve time management:\n",
        "Set Clear Goals: Break big tasks into smaller, manageable steps to stay focused.\n",
        "Create a Daily Schedule: Use a planner, to-do list, or a digital calendar to allocate time for work, exercise, and relaxation.\n",
        "Focus on One Task at a Time: Avoid multitasking, as it can reduce efficiency and lead to mistakes.\n",
        "Review and Adjust Your Schedule: At the end of each day or week, check your progress and make adjustments to improve.\n",
        "By practicing good time management, I have been able to stay organized, reduce stress, and maintain a healthy balance between work and personal life. Anyone who follows these simple steps can also increase productivity and achieve a well-balanced life.\n",
        "\n",
        "\n",
        "Life Improvement\n",
        "Can you talk about a time when you made a positive change in either your life or someone else's life? What made you decide to make this change, and what did you do to make it happen? Were there any difficulties you faced during this process, and how did you overcome them? Lastly, how has this change affected your life or the lives of others in a positive way, and what did you learn from the experience?\n",
        "\n",
        "There was a time when I decided to improve my physical health by following a regular exercise routine. I noticed that I often felt tired and stressed, which affected my mood, energy levels, and productivity. I knew that making a change in my lifestyle would help me feel better and work more efficiently.\n",
        "Steps I Took:\n",
        "I started with short workouts of 15-20 minutes to make the habit easier to follow.\n",
        "Gradually, I increased the intensity and duration as my body adapted.\n",
        "I made sure to work out 4-5 times a week and also improved my diet by eating healthier food.\n",
        "Challenges I Faced:\n",
        "One of the biggest challenges was managing time for exercise in my daily routine. Some days, I also struggled with staying motivated, especially when I didn’t see quick results.\n",
        "How I Overcame These Challenges:\n",
        "Tracking my progress helped me stay motivated by seeing small improvements over time.\n",
        "I scheduled my workouts during breaks to make them fit easily into my daily routine.\n",
        "On days when I lacked motivation, I reminded myself of why I started and how much better I felt after exercising.\n",
        "Results & Positive Impact:\n",
        "My energy levels increased, and I felt more active and less stressed throughout the day.\n",
        "My productivity improved, as I could focus better on my work.\n",
        "Seeing my progress, some of my friends and family members also started adopting healthier habits.\n",
        "Lesson Learned:\n",
        "This experience taught me the importance of self-care, staying consistent, and taking small steps towards big goals. Even small daily efforts can lead to major positive changes over time.\n",
        "\n",
        "\n",
        "Best Policy\n",
        "Many people believe that honesty is the best policy. In your opinion, is it ever okay to lie?\n",
        "Could you explain your answer using a specific reasons and examples\n",
        "\n",
        "Many people believe that honesty is the best policy, and I mostly agree with this idea. Being honest helps build trust, strong relationships, and transparency in both personal and professional life. However, I also believe that there are some rare situations where withholding the truth or slightly modifying it might be acceptable—especially when the intention is to protect someone's emotions or prevent unnecessary harm.\n",
        "Example:\n",
        "Let’s say a colleague has worked hard on a presentation, but the final outcome isn’t very impressive. Instead of being completely blunt and pointing out every single flaw, I would choose to focus on the positive aspects first and then offer constructive feedback in a private and encouraging way. This approach helps the person stay motivated and improve their work without feeling discouraged.\n",
        "Balancing Honesty and Sensitivity:\n",
        "While being truthful is important, it’s equally important to communicate thoughtfully so that the truth doesn’t hurt others unnecessarily. The key is to be ethical and responsible when handling such situations.\n",
        "In conclusion, honesty should always be a priority, but in some cases, kindness and empathy should also be considered when deciding how to deliver the truth.\n",
        "\n",
        "\n",
        "Lottery Winner\n",
        "Write about what you would do if you won a 1 crore rupee lottery\n",
        "\n",
        "If I were to win a 1 crore rupee lottery, I would make sure to use the money wisely rather than spending it all at once. Here’s how I would approach it:\n",
        "Financial Planning:\n",
        "The first and most important step would be to consult a financial advisor. This would help me invest a portion of the money wisely so that I can secure my future. I would also keep some money aside for important future expenses, such as education, healthcare, and emergencies.\n",
        "Debt Repayment:\n",
        "If I had any outstanding debts, I would clear them immediately. This would reduce financial stress and help me maintain better financial stability in the long run.\n",
        "Charity and Giving Back:\n",
        "I strongly believe in helping others, so I would donate a portion of my winnings to charitable causes. This could include education, healthcare, and support for underprivileged communities. Giving back to society would bring me immense satisfaction.\n",
        "Personal Enjoyment:\n",
        "Of course, I would also treat myself—but in a balanced way. I might go on a vacation, upgrade my lifestyle, or buy something I’ve always wanted. However, I would be careful not to overspend and keep my focus on long-term benefits.\n",
        "Supporting Family & Friends:\n",
        "If my family members or close friends needed support, I would help them out—whether it’s for education, healthcare, or starting a business. Helping loved ones improve their lives would be a rewarding experience.\n",
        "Final Thoughts:\n",
        "Winning a lottery is a once-in-a-lifetime opportunity, but using the money wisely is what truly matters. Instead of spending recklessly, I would focus on long-term security, personal fulfillment, and making a positive impact on others' lives.\n",
        "\n",
        "\n",
        "Parent's Appreciation\n",
        "Talk about reasons for appreciation your parents\n",
        "\n",
        "I have deep appreciation for my parents for many reasons. Their love, sacrifices, and guidance have played a major role in shaping the person I am today.\n",
        "Unconditional Support:\n",
        "My parents have always been there for me, no matter what. Whether I was struggling emotionally or financially, they stood by my side and encouraged me to keep going. Even when I doubted myself, they believed in me, which gave me the strength to overcome challenges.\n",
        "Sacrifices:\n",
        "They have made countless sacrifices to ensure I had the best opportunities in life. From prioritizing my education over their own needs to working extra hours so I never felt deprived, their selflessness is something I truly admire.\n",
        "Values & Teachings:\n",
        "My parents taught me the importance of honesty, hard work, and kindness. Their guidance and wisdom have helped me become a responsible and empathetic person, always willing to help others.\n",
        "Patience & Understanding:\n",
        "They have always been patient listeners, allowing me to express my thoughts freely without fear of judgment. Their understanding nature has created a safe space where I could share my concerns and dreams openly.\n",
        "Work Ethic & Dedication:\n",
        "Their strong work ethic and commitment to providing for our family have been a huge inspiration for me. Watching their determination has motivated me to always give my best effort in everything I do.\n",
        "Final Thoughts:\n",
        "I am truly grateful for everything my parents have done for me. Their love, support, and teachings have had an immeasurable impact on my life, and I will always cherish and appreciate them.\n",
        "\n",
        "\n",
        "Ways to appreciate\n",
        "Write about ways to appreciate your parents\n",
        "\n",
        "There are many ways to show appreciation to our parents for everything they have done for us. Even small gestures can make them feel loved and valued. Here are some simple and meaningful ways to express gratitude:\n",
        "Express Gratitude:\n",
        "A simple \"Thank you\" can mean a lot. Regularly acknowledging their efforts and letting them know how much you appreciate their love and support can make them feel truly special.\n",
        "Spend Quality Time:\n",
        "Parents don’t always expect grand gestures—sometimes, they just want to spend time with us. Engage in activities they enjoy, whether it's watching a movie together, going for a walk, or just having a heartfelt conversation.\n",
        "Listen to Them:\n",
        "Parents have many experiences and stories to share. Taking the time to listen to their thoughts, concerns, and advice makes them feel heard and respected.\n",
        "Help Out:\n",
        "Helping with household chores or tasks can reduce their workload and show that you care about their well-being. Small actions like cooking a meal, running errands, or fixing something at home can bring them joy.\n",
        "Surprise Them:\n",
        "Thoughtful surprises, like giving a small gift, writing a heartfelt note, or planning a special day for them, can make them feel loved and appreciated.\n",
        "Acknowledge Their Efforts:\n",
        "Recognizing their hard work and sacrifices can make a big difference. Saying things like, \"I know how much you have done for me, and I truly appreciate it\" reassures them that their efforts are valued.\n",
        "Final Thought:\n",
        "Appreciating parents doesn’t always require big actions. Small and consistent gestures of love, respect, and gratitude can make them feel cherished and happy.\n",
        " \"\"\""
      ],
      "metadata": {
        "id": "sCdIh7wALH4R"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Result\n",
        "text_to_speech(name, text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42W0D_hf9HMy",
        "outputId": "e9d30b99-44af-4b26-8b5d-df626ce895ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MP3 file 'Self Assessment.mp3' has been generated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = \"Technical Fluency part-1.mp3\""
      ],
      "metadata": {
        "id": "BuQ4C-eKa9Fa"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Information Gain\n",
        "What is Information Gain?\n",
        "Information Gain (I G) is a concept used in Machine Learning to measure how well a particular decision or split reduces uncertainty or \"messiness\" in data. It's commonly used in decision trees to decide the best way to split data at each step.\n",
        "In simple terms, it tells us how much \"information\" we gain by splitting data based on a particular feature. The more information gained, the better the feature is for making decisions. It's often used in decision trees to decide which feature to split on at each step.\n",
        "For example, if we are trying to predict whether someone will buy a product, a feature like \"age\" may give us more information about the prediction than a feature like \"hair color.\"\n",
        "The idea is that after we split the data based on a feature, the resulting groups should be more uniform or pure in terms of the target variable. The more uniform they are, the higher the information gain.\n",
        "\n",
        "R square and adjusted R square\n",
        "What is the primary difference between R square and adjusted R square\n",
        "R-squared measures how well the independent variables in your model explain the variation in the dependent variable. It increases as you add more variables, even if those variables are not meaningful.\n",
        "Adjusted R-squared adjusts R-squared for the number of predictors in the model. It penalizes you for adding variables that don't improve the model, helping to avoid overfitting.\n",
        "In simple terms, R-squared tells you the goodness of fit, while adjusted R-squared gives a more accurate measure by considering the number of predictors in your model.\n",
        "\n",
        "P Value\n",
        "What is the PValue and how do i interpret it\n",
        "The p-value is a number that helps you understand whether the results of an experiment or test are statistically significant. In simple terms, it tells you how likely it is that your results happened by chance.\n",
        "A low p-value (usually less than 0.05) suggests that the results are unlikely to have happened by chance, meaning there's likely a real effect or difference.\n",
        "A high p-value (greater than 0.05) suggests that the results are likely due to random chance, meaning there's no strong evidence of an effect.\n",
        "In short:\n",
        "p-value < 0.05: The result is statistically significant (the effect is likely real).\n",
        "p-value ≥ 0.05: The result is not statistically significant (the effect could be due to chance).\n",
        "\n",
        "Ensemble Learning\n",
        "Ensemble learning is a technique in machine learning where multiple models (also called \"learners\") are combined to solve a problem. The idea is that by using a group of models instead of just one, the overall prediction is usually more accurate. It’s like asking a group of experts for an opinion instead of just one — the more opinions, the better the chance of getting it right.\n",
        "There are different ways to combine these models:\n",
        "Bagging: Each model is trained on different parts of the data and their predictions are averaged or voted on.\n",
        "Boosting: Models are built one after another, each trying to fix the mistakes of the previous one.\n",
        "Stacking: Multiple models are trained, and then another model combines their predictions.\n",
        "Ensemble learning helps improve accuracy and reduce errors by leveraging the strength of multiple models.\n",
        "\n",
        "Bias  Variance Tradeoff\n",
        "The Bias-Variance Tradeoff is a concept in machine learning that describes the balance between two types of errors that can affect a model's performance:\n",
        "Bias: This is the error introduced by assuming a simpler model than what is needed. A high bias means the model makes strong assumptions and misses important patterns in the data. It usually leads to underfitting, where the model doesn't perform well on both training and test data.\n",
        "Variance: This is the error introduced by a model that is too complex and sensitive to small changes in the training data. A high variance means the model is likely overfitting, learning noise or random fluctuations in the data instead of general patterns, which leads to poor performance on new, unseen data.\n",
        "The tradeoff means that when you try to reduce one type of error (e.g., bias), the other (e.g., variance) may increase. The goal is to find the right balance where both bias and variance are minimized, allowing the model to generalize well to new data.\n",
        "\n",
        "Confidence Interval\n",
        "What is a Confidence Interval?\n",
        "A Confidence Interval is a range of values that estimates where the true value of something (like an average or proportion) is likely to fall. It’s like saying, \"We are pretty sure that the true value is somewhere between these two numbers.\"\n",
        "For example, if a survey says that the average height of people in a city is between 5'6\" and 5'8\" with 95% confidence, it means that if we repeated the survey many times, 95% of the time the true average height would fall within that range.\n",
        "\n",
        "Bagging and Boosting\n",
        "What is the difference between Bagging and Boosting?\n",
        "Bagging and Boosting are both techniques used to improve the performance of machine learning models, but they work in different ways:\n",
        "Bagging (Bootstrap Aggregating):\n",
        "It creates multiple models by training on different random subsets of the data.\n",
        "Each model is built independently and equally contributes to the final prediction (usually by averaging or voting).\n",
        "The idea is to reduce variance and avoid overfitting.\n",
        "Boosting:\n",
        "It builds models sequentially, where each new model tries to correct the mistakes made by the previous one.\n",
        "The models are weighted based on their performance, and stronger models get more focus.\n",
        "The goal is to reduce both bias and variance by improving accuracy step by step.\n",
        "In short:\n",
        "Bagging reduces variance by combining multiple models independently.\n",
        "Boosting reduces both bias and variance by focusing on improving weak models sequentially.\n",
        "\n",
        "Naive Bayes\n",
        "Naive Bayes is a simple and fast machine learning algorithm used for classification tasks. It works by assuming that the features (or attributes) of the data are independent of each other, which is why it's called \"naive.\" Even though this assumption is often not true in real life, Naive Bayes can still perform well in many situations.\n",
        "The algorithm calculates the probability of a class label given the features of the data, and it assigns the label with the highest probability. It's commonly used for spam detection, sentiment analysis, and document classification.\n",
        "In short:\n",
        "It uses probabilities to make predictions.\n",
        "Assumes features are independent.\n",
        "It's simple and works well with a lot of data.\n",
        "\n",
        "High bias model\n",
        "A high bias model is one that makes strong assumptions about the data, leading to underfitting. It oversimplifies the problem and fails to capture the underlying patterns, resulting in poor performance on both training and test data.\n",
        "Key Points:\n",
        "Underfitting: Poor performance due to simplicity.\n",
        "Low variance: Doesn't change much across datasets.\n",
        "Solutions:\n",
        "Use a more complex model.\n",
        "Add more features.\n",
        "Reduce regularization.\n",
        "Example: A linear model predicting house prices using only square footage is too simple and misses other important factors like location.\n",
        "\n",
        "Cross Validation\n",
        "Cross Validation is a technique used to evaluate the performance of a machine learning model by splitting the data into multiple subsets. It helps to ensure that the model generalizes well to unseen data and avoids overfitting.\n",
        "Types:\n",
        "K Fold cross validation:\n",
        "The dataset is divided into 'K' subsets (or folds).\n",
        "The model is trained on K1 folds and tested on the remaining fold.\n",
        "This is repeated K times, with each fold used as the test set once.\n",
        "Leave One Out cross validation (LOOCV):\n",
        "A special case of Kfold where K equals the number of data points.\n",
        "Each data point is used once as a test set, and the rest for training.\n",
        "Benefits:\n",
        "Helps in obtaining a more reliable estimate of model performance.\n",
        "Reduces bias and variance compared to a single traintest split.\n",
        "\n",
        "Support Vector Machine\n",
        "Support Vector Machine (SVM) is a supervised machine learning algorithm used for classification and regression. It works by finding a hyperplane that best separates data points into different classes.\n",
        "Key Concepts:\n",
        "Hyperplane: A boundary that separates different classes.\n",
        "Support Vectors: Points closest to the hyperplane that influence its position.\n",
        "Margin: The distance between the hyperplane and the support vectors.\n",
        "Types:\n",
        "Linear SVM: Used for linearly separable data.\n",
        "Nonlinear SVM: Uses kernel functions for nonlinearly separable data.\n",
        "Advantages:\n",
        "Effective in high dimensional spaces.\n",
        "Robust overfitting.\n",
        "Disadvantages:\n",
        "Computationally expensive.\n",
        "Selecting the right kernel can be tricky.\n",
        "SVM is used in image classification, text classification, and bioinformatics.\n",
        "\n",
        "Logistic Regression or Classification\n",
        "Logistic Regression is a classification algorithm used for binary outcomes (e.g., yes no). It predicts probabilities using the sigmoid function, which maps inputs to a value between 0 and 1.\n",
        "Key Points:\n",
        "Sigmoid function: Maps linear combinations of features to a probability.\n",
        "Logodds: The model estimates the logodds of the event happening.\n",
        "Steps:\n",
        "Train: Fit the model to data.\n",
        "Predict: Output probabilities and classify based on a threshold (e.g., >0.5 = 1, else 0).\n",
        "Advantages:\n",
        "Simple and efficient for linear relationships.\n",
        "Disadvantages:\n",
        "Assumes a linear relationship, may not work well for complex patterns.\n",
        "\n",
        "Bias in ML\n",
        "Bias in Machine Learning refers to errors that lead to inaccurate or unfair predictions, arising from simplifications in data, models, or training.\n",
        "Types of Bias:\n",
        "Data Collection: Unrepresentative or inconsistent data.\n",
        "Feature Selection: Bias in features favoring certain outcomes.\n",
        "Algorithmic: Oversimplified models or overfitting.\n",
        "Evaluation: Nonrepresentative test validation data.\n",
        "Causes:\n",
        "Poor data quality, human errors, and historical inequalities.\n",
        "Effects:\n",
        "Inaccurate predictions, unfair outcomes, loss of trust, and poor generalization.\n",
        "Mitigation:\n",
        "Data diversification, fairness aware algorithms, bias detection, transparent AI, and regular monitoring.\n",
        "Techniques:\n",
        "Resampling, reweighting, and adversarial debiasing.\n",
        "Conclusion:\n",
        "Addressing bias ensures fair, accurate, and responsible AI systems.\n",
        "\n",
        "Curse of Dimensionality\n",
        "How λ relates to the principle of \"Curse of Dimensionality\"?\n",
        "The \"Curse of Dimensionality\" refers to challenges in high dimensional datasets, where the feature space grows exponentially, causing issues such as overfitting, increased computation, and data sparsity. Regularization techniques like Lasso (L1) and Ridge (L2) regression use the parameter λ (lambda) to address these challenges effectively:\n",
        "Controlling Model Complexity:\n",
        "High Dimensional models risk overfitting by capturing noise along with patterns.\n",
        "λ penalizes large coefficients, simplifying the model, reducing variance, and enhancing generalizability.\n",
        "Feature Selection and Dimensionality Reduction:\n",
        "Lasso regression uses λ to shrink some coefficients to zero, removing irrelevant features and mitigating data sparsity.\n",
        "BiasVariance Tradeoff:\n",
        "λ balances bias and variance by increasing bias (simplifying the model) and reducing variance, managing the risks of high dimensional data.\n",
        "In summary, λ mitigates the Curse of Dimensionality by reducing model complexity, aiding feature selection, and optimizing the bias variance tradeoff, making models more efficient and robust.\n",
        "\n",
        "Hyperparameters Tuning and C V\n",
        "What are methods for tuning hyperparameters? Explain all in brief.\n",
        "Hyperparameter tuning is the process of optimizing a machine learning model's hyperparameters to improve performance and avoid overfitting or underfitting.\n",
        "Key methods include:\n",
        "Manual Search: Simple trial and error, practical for small models but time consuming for complex ones.\n",
        "Grid Search: Exhaustively evaluates all combinations of hyperparameter values; effective for small parameter spaces but computationally expensive.\n",
        "Random Search: Randomly samples hyperparameters, offering efficient exploration for large search spaces, often matching Grid Search in effectiveness.\n",
        "Bayesian Optimization: Uses probabilistic models to focus on promising hyperparameter regions, balancing exploration and exploitation; highly efficient.\n",
        "GradientBased Optimization: Adjusts differentiable hyperparameters (e.g., learning rates) using gradients, mostly used in neural networks.\n",
        "Evolutionary Optimization: Simulates natural selection to evolve optimal hyperparameter combinations; useful for complex models but computationally intensive.\n",
        "Automated Libraries (AutoML): Tools like Optuna and AutoSklearn automate tuning using advanced techniques like Bayesian or Random Search.\n",
        "CrossValidation (CV): Combines tuning methods with multiple data splits to ensure hyperparameters generalize well and reduce overfitting.\n",
        "Efficient tuning often involves combining methods, such as starting with Random Search and refining with Bayesian Optimization.\n",
        "\n",
        "K means Clustering\n",
        "What is K means Clustering Algorithm? Is Feature Scaling required for the K means Algorithm?\n",
        "KMeans Clustering is an unsupervised machine learning algorithm used to divide data into K clusters based on feature similarity by minimizing the variance within clusters.\n",
        "How It Works:\n",
        "Select K: Determine the number of clusters.\n",
        "Initialize Centroids: Randomly place K centroids in the data space.\n",
        "Assign Points: Assign each data point to the nearest centroid.\n",
        "Update Centroids: Recalculate centroids as the mean of points in each cluster.\n",
        "Repeat: Iterate until cluster assignments stabilize or centroids stop moving significantly.\n",
        "The goal is to minimize the WithinCluster Sum of Squares (WCSS).\n",
        "Feature Scaling in KMeans:\n",
        "Required because KMeans relies on Euclidean distance, which can be biased if features have different scales.\n",
        "Improves Accuracy and Convergence by ensuring all features contribute equally.\n",
        "Common Scaling Techniques:\n",
        "Standardization (Zscore Normalization): Rescales data to have a mean of 0 and standard deviation of 1.\n",
        "MinMax Scaling: Rescales features to a fixed range, usually [0, 1].\n",
        "In summary, feature scaling is essential for accurate and unbiased clustering results in KMeans.\n",
        "\n",
        "KNN Algorithm\n",
        "What is K in KNN Algorithm? Why is KNN a non parametric Algorithm?\n",
        "In the KNearest Neighbors (KNN) algorithm, K determines the number of nearest neighbors used for predictions:\n",
        "For classification: Assigns the majority class of the K neighbors.\n",
        "For regression: Predicts as the average (or weighted average) of the K neighbors.\n",
        "Choosing K:\n",
        "Small K (e.g., K=1): High sensitivity to noise, risk of overfitting.\n",
        "Large K: Smoother predictions but may miss local patterns.\n",
        "The optimal K is often selected via crossvalidation.\n",
        "Why KNN is NonParametric:\n",
        "No Assumptions About Data Distribution: Unlike parametric models, KNN does not assume a specific data structure or equation.\n",
        "No Training Phase: KNN stores data and makes predictions by comparing distances during testing (lazy learning).\n",
        "Adaptability: Dynamically adjusts to the data’s local structure without predefined parameters.\n",
        "Summary: K defines the neighbors influencing predictions, and KNN is nonparametric as it relies solely on distancebased decisions without requiring a trained model or assumptions about data.\n",
        "\n",
        "\n",
        "SMOTE in Brief\n",
        "Explain SMOTE\n",
        "SMOTE (Synthetic Minority Oversampling Technique) is an oversampling technique used to address the class imbalance problem in machine learning. It is particularly useful when you have an imbalanced dataset, where one class has significantly fewer samples than the other, which can lead to biased models.\n",
        "SMOTE is a popular technique for handling imbalanced datasets, especially when dealing with binary classification or multiclass problems. It helps generate synthetic examples of the minority class to balance the dataset and improve the performance of machine learning models. However, it should be used carefully, and it's important to assess the performance of the model after applying SMOTE to ensure that it does not introduce noise or overfitting.\n",
        "\n",
        "Regularization\n",
        "Regularization prevents overfitting by adding a penalty to the model’s complexity.\n",
        "Types:\n",
        "L1 Regularization (Lasso): Shrinks some coefficients to zero, performing feature selection.\n",
        "L2 Regularization (Ridge): Shrinks coefficients but doesn’t eliminate features.\n",
        "Elastic Net: Combines both L1 and L2 regularization.\n",
        "Benefits:\n",
        "Reduces overfitting.\n",
        "Improves generalization.\n",
        "Helps in highdimensional data.\n",
        "It works by adding a penalty term to the model, limiting large weights and preventing the model from fitting noise.\n",
        "\n",
        "High variance model\n",
        "What are the solutions for the high variance model\n",
        "To address high variance (overfitting) in a model:\n",
        "Simplify the Model: Use a simpler model with fewer parameters.\n",
        "Increase Training Data: Collect more data or use data augmentation.\n",
        "Regularization: Apply L1 (Lasso) or L2 (Ridge) regularization to reduce model complexity.\n",
        "CrossValidation: Use kfold or LOOCV to validate model performance on different data subsets.\n",
        "Ensemble Methods: Use bagging (Random Forest) or boosting (XGBoost) to reduce variance.\n",
        "Early Stopping: In neural networks, stop training when performance starts to degrade on the validation set.\n",
        "Feature Selection: Remove irrelevant features or use PCA to reduce dimensionality.\n",
        "\n",
        "Pruning\n",
        "Why do we require pruning in decision trees? Explain\n",
        "Pruning in decision trees is the process of removing parts of the tree that do not provide significant power in predicting target values. It is used to address overfitting and improve the generalization ability of the model.\n",
        "Why Pruning is Required:\n",
        "Avoid Overfitting: A decision tree may fit the training data very well but fail to generalize to new data. Pruning helps by removing branches that capture noise and outliers in the training data.\n",
        "Simplify the Model: A deep tree with many branches can be complex and harder to interpret. Pruning reduces the complexity of the model, making it easier to understand and faster to compute.\n",
        "Improve Performance on Unseen Data: By removing unnecessary branches, pruning helps the tree perform better on unseen or validation data, thus increasing its accuracy.\n",
        "Reduce Model Size: Pruning reduces the size of the tree, which can be beneficial in terms of memory and computation resources, especially in large datasets.\n",
        "Types of Pruning:\n",
        "Prepruning: Stopping the growth of the tree early based on certain conditions (e.g., maximum depth, minimum samples per leaf).\n",
        "Postpruning: Growing the tree fully and then pruning branches that provide little value in improving prediction accuracy (e.g., costcomplexity pruning).\n",
        "Pruning helps balance bias and variance, leading to better model performance on realworld data.\n",
        "\n",
        "Gini impurity or Entropy\n",
        "Which should be preferred among gini impurity or Entropy\n",
        "Gini Impurity and Entropy are both used to measure the quality of splits in decision trees.\n",
        "Gini Impurity is computationally simpler and measures the probability of incorrect classification. It ranges from 0 (pure) to 0.5 (impure).\n",
        "Entropy measures uncertainty or disorder in the data and ranges from 0 (pure) to log⁡2(C)\\log_2(C)log2​(C), where CCC is the number of classes.\n",
        "Which to Prefer?\n",
        "Gini Impurity is faster to compute and often preferred in practice for decision trees, as it usually leads to simpler and more balanced trees.\n",
        "Entropy may create deeper trees but is computationally more expensive.\n",
        "In general, Gini Impurity is preferred for its simplicity and efficiency.\n",
        "\n",
        "Logistic Regression\n",
        "What are the assumptions made in LR\n",
        "The assumptions made in Logistic Regression are:\n",
        "Linear relationship: There is a linear relationship between the independent variables (predictors) and the log odds of the dependent variable.\n",
        "Independence: Observations are independent of each other (i.e., no autocorrelation).\n",
        "No multicollinearity: The independent variables should not be highly correlated with each other, as it can affect the stability of the coefficient estimates.\n",
        "Binary outcome: Logistic regression assumes a binary outcome (i.e., two possible outcomes: 0 or 1), though it can be extended to multiclass problems (multinomial logistic regression).\n",
        "Large sample size: Logistic regression generally works well with a large enough sample size, as the estimation of coefficients using Maximum Likelihood Estimation (MLE) can be sensitive to small samples.\n",
        "Homoscedasticity: The variance of the error terms should be constant across all values of the independent variables.\n",
        "\n",
        "Overfitting in Linear Models\n",
        "How would you detect overfitting in linear models\n",
        "Overfitting in Linear Models can be detected through the following methods:\n",
        "Training vs. Test Performance:\n",
        "If the model performs well on the training data but poorly on the test data (significantly higher error on the test set), it indicates overfitting.\n",
        "The gap between training and test performance should be minimal for a wellgeneralized model.\n",
        "CrossValidation:\n",
        "Use kfold crossvalidation to evaluate the model on different subsets of the data. If the performance varies greatly across folds, it might indicate overfitting to a particular subset of the data.\n",
        "Model Complexity:\n",
        "Check if the model has too many features (especially irrelevant ones) or overly complex polynomial terms. A complex model is more likely to overfit the training data.\n",
        "Coefficient Magnitude:\n",
        "In linear regression, very large or unstable coefficients (especially when regularization is not used) might indicate overfitting.\n",
        "Residual Analysis:\n",
        "Plot the residuals (differences between predicted and actual values). If residuals exhibit patterns or nonrandomness, the model might not generalize well, suggesting overfitting.\n",
        "Validation Metrics:\n",
        "Use metrics such as Mean Squared Error (MSE) or Rsquared on both training and validation datasets. If the model has a high Rsquared on training but low on validation data, overfitting is likely.\n",
        "Learning Curves:\n",
        "Plot learning curves for both training and validation datasets. If the training error keeps decreasing but the validation error starts increasing, overfitting is happening.\n",
        "\n",
        "Hyperparameters Tuning\n",
        "What is hyperparameters tuning and crossvalidation?\n",
        "Hyperparameter Tuning:\n",
        "Hyperparameter tuning refers to the process of finding the optimal values for the hyperparameters of a machine learning model. Hyperparameters are the parameters that are set before training the model (e.g., learning rate, number of trees in a random forest, kernel type in SVM, etc.).\n",
        "The goal of hyperparameter tuning is to improve the model’s performance on unseen data by selecting the best combination of hyperparameters.\n",
        "Common techniques for hyperparameter tuning include:\n",
        "Grid Search: Exhaustively trying all combinations of hyperparameters in a predefined grid.\n",
        "Random Search: Randomly sampling the hyperparameters from a defined search space.\n",
        "Bayesian Optimization: A probabilistic modelbased approach to search the hyperparameter space more efficiently.\n",
        "CrossValidation:\n",
        "Crossvalidation is a technique used to evaluate a model’s performance and ensure it generalizes well to unseen data. It involves splitting the dataset into multiple subsets or folds, training the model on some folds and testing it on the remaining folds.\n",
        "The most common form is kfold crossvalidation:\n",
        "The data is divided into k equal parts (or folds).\n",
        "The model is trained on k1 folds and tested on the remaining fold.\n",
        "This process is repeated k times, with each fold serving as the test set once.\n",
        "The results are averaged to provide a more reliable estimate of model performance.\n",
        "Crossvalidation helps prevent overfitting and provides a better estimate of a model’s generalization ability.\n",
        "Summary:\n",
        "Hyperparameter tuning adjusts model settings to improve performance.\n",
        "Crossvalidation helps evaluate and validate model performance by using multiple data splits.\n",
        "\n",
        "Hypothesis Testing\n",
        "What is hypothesis testing\n",
        "Hypothesis Testing is a statistical method used to make inferences or draw conclusions about a population based on a sample of data. It involves two competing hypotheses:\n",
        "Null Hypothesis (H₀): The statement that there is no effect or no difference, or that a parameter is equal to a specific value.\n",
        "Alternative Hypothesis (H₁ or Ha): The statement that there is an effect or a difference, or that a parameter is not equal to a specific value.\n",
        "Steps in Hypothesis Testing:\n",
        "Formulate Hypotheses: Define the null and alternative hypotheses.\n",
        "Select Significance Level (α): Choose the probability of rejecting the null hypothesis when it is actually true, usually set at 0.05.\n",
        "Calculate Test Statistic: Use sample data to compute a test statistic (e.g., tstatistic, zscore).\n",
        "Make a Decision: Compare the test statistic to a critical value or use the pvalue to decide whether to reject or fail to reject the null hypothesis.\n",
        "Conclusion: Based on the decision, conclude if there is enough evidence to support the alternative hypothesis.\n",
        "Example:\n",
        "Null Hypothesis: The average height of a group is 170 cm.\n",
        "Alternative Hypothesis: The average height of a group is not 170 cm.\n",
        "If the test gives a pvalue less than α, we reject the null hypothesis. Otherwise, we fail to reject it.\n",
        "\n",
        "Central Limit Theorem\n",
        "What is central limit theorem?\n",
        "The Central Limit Theorem (CLT) states that the distribution of the sample mean of a large enough number of independent, identically distributed random variables will be approximately normal, regardless of the population's distribution.\n",
        "Key Points:\n",
        "As the sample size increases (typically >30), the sample means follow a normal distribution.\n",
        "This holds true even if the population isn't normally distributed.\n",
        "Importance:\n",
        "CLT allows for statistical inferences like hypothesis testing and confidence intervals, even with nonnormal populations.\n",
        "\n",
        "Dimensionality Reduction\n",
        "What are DR and its benefit\n",
        "Dimensionality Reduction (DR) is a technique used to reduce the number of features (variables) in a dataset while retaining as much of the important information as possible. It is often applied to highdimensional datasets to simplify the data and improve computational efficiency.\n",
        "Benefits of Dimensionality Reduction:\n",
        "Improved Performance:\n",
        "Reduces overfitting by eliminating irrelevant features, improving model generalization.\n",
        "Leads to faster model training as fewer features mean fewer computations.\n",
        "Reduced Complexity:\n",
        "Helps in visualizing highdimensional data by projecting it to lower dimensions (e.g., 2D or 3D).\n",
        "Noise Reduction:\n",
        "By removing less important features, dimensionality reduction can help reduce noise and make the data more manageable for modeling.\n",
        "Better Interpretation:\n",
        "By reducing the number of features, it becomes easier to understand and interpret the relationships in the data.\n",
        "Storage and Computational Efficiency:\n",
        "Reduces the memory and storage requirements, making it easier to handle large datasets.\n",
        "\n",
        "Principal Component Analysis (PCA)\n",
        "Principal Component Analysis (PCA) is a dimensionality reduction technique that simplifies complex datasets by transforming them into a smaller set of uncorrelated variables called principal components, which retain most of the original data's variance. It involves three key steps: standardizing the data, calculating the covariance matrix, and finding the eigenvectors and eigenvalues to identify the most significant components. By selecting the top principal components, PCA reduces the number of features, making it easier to analyze and visualize the data. It’s commonly used for noise reduction, feature selection, and data visualization in fields like machine learning and finance.\n",
        "\n",
        "Random Forest\n",
        "Random Forest is an ensemble learning algorithm that combines multiple decision trees to make predictions. Each tree is trained on a random subset of the data and features, helping to reduce overfitting and increase model accuracy. In classification tasks, it predicts the class by majority voting, while in regression tasks, it averages the predictions of all trees. Random Forest is robust, handles both numerical and categorical data, and is effective with large datasets. It is widely used in tasks like classification, regression, and feature selection due to its high performance and ease of use.\n",
        "\n",
        "Decision Tree\n",
        "A Decision Tree is a supervised machine learning algorithm used for both classification and regression tasks. It splits the data into subsets based on feature values, creating a treelike structure with decision nodes and leaf nodes. Each decision node represents a feature test, and each leaf node represents an outcome or prediction. The tree is built by recursively choosing the best feature that splits the data to maximize information gain or minimize impurity (e.g., Gini index, entropy). Decision Trees are easy to interpret and visualize, but they can overfit if not properly tuned, which is why ensemble methods like Random Forests are often used.\n",
        "\n",
        "Ridge Regression\n",
        "Ridge regression is a type of linear regression that helps prevent overfitting by adding a penalty to the size of the coefficients. In simple words, it’s a method used when building a model to predict something (like house prices or sales) where we want to avoid making the model too complex or overly influenced by outliers.\n",
        "It works by adding a small amount to the sum of the squares of the model’s coefficients. This discourages the model from making its coefficients too large, which could lead to overfitting (where the model performs well on training data but poorly on new data).\n",
        "In short, ridge regression helps create a more reliable and generalizable model by keeping the coefficients smaller and more controlled.\n",
        "\n",
        "L1 and L2 Regularization\n",
        "L1 and L2 regularization are techniques used to prevent overfitting in machine learning models by adding a penalty to the model's complexity.\n",
        "L1 Regularization (Lasso):\n",
        "Adds the absolute values of the model's weights to the loss function.\n",
        "This encourages the model to use fewer features, effectively performing feature selection.\n",
        "It can make some weights exactly zero, which simplifies the model.\n",
        "L2 Regularization (Ridge):\n",
        "Adds the squared values of the model's weights to the loss function.\n",
        "It helps reduce the impact of less important features by shrinking their weights.\n",
        "It doesn’t make weights exactly zero, but it keeps them small.\n",
        "In short:\n",
        "L1 helps create simpler models by eliminating features.\n",
        "L2 keeps the model smooth by making weights small.\n",
        "\n",
        "Lasso Regression\n",
        "Lasso Regression is a type of linear regression that helps to predict an outcome based on one or more input features. The main difference is that it adds a penalty to the model for using too many features. This penalty helps to simplify the model by making some of the less important features have a coefficient of zero, effectively removing them from the model. This process is known as \"regularization.\"\n",
        "In simple terms:\n",
        "It predicts a value based on inputs.\n",
        "It tries to make the model as simple as possible by removing unnecessary features.\n",
        "It helps prevent overfitting (when the model fits the data too closely, losing its ability to generalize to new data).\n",
        "The \"Lasso\" part stands for \"Least Absolute Shrinkage and Selection Operator.\"\n",
        "\n",
        "Elastic Net Regression\n",
        "Elastic Net Regression is a type of regression technique that combines two methods: Ridge Regression and Lasso Regression.\n",
        "Ridge Regression helps to shrink the coefficients (the numbers in the equation) to prevent overfitting by adding a penalty for large coefficients.\n",
        "Lasso Regression also adds a penalty but can shrink some coefficients completely to zero, essentially selecting the most important features.\n",
        "Elastic Net combines both techniques, allowing it to handle situations where there are many features, some of which may not be important. It helps in creating a model that is more accurate and easier to interpret by selecting relevant features and reducing overfitting.\n",
        "In simple terms, Elastic Net is like a mix of two methods that helps to build a more reliable and interpretable model, especially when there are many features in the data.\n",
        "\n",
        "OneHot Encoding\n",
        "OneHot Encoding is a method used in Machine Learning to convert categorical data into a numerical format so that algorithms can understand it.\n",
        "Here’s how it works:\n",
        "Suppose we have a feature called \"Color\" with three categories: Red, Green, and Blue. Since computers cannot process text directly, we create separate columns for each category.\n",
        "For example:\n",
        "If the color is Red, the data becomes:\n",
        "Color_Red = 1, Color_Green = 0, Color_Blue = 0\n",
        "If the color is Green, it becomes:\n",
        "Color_Red = 0, Color_Green = 1, Color_Blue = 0\n",
        "This way, each category is represented using 0s and 1s, ensuring that the model does not assume any order or ranking between them. OneHot Encoding helps Machine Learning models understand categorical data in a better way.\n",
        "\n",
        "Label Encoding\n",
        "Label Encoding is a method used in Machine Learning to convert categorical data into numbers by assigning a unique integer to each category.\n",
        "It is useful when the categories have a natural order (ordinal relationship). For example, if we have a \"Size\" feature with values:\n",
        "Small → 0\n",
        "Medium → 1\n",
        "Large → 2\n",
        "This means Small < Medium < Large, which makes sense because size follows a logical order.\n",
        "However, Label Encoding can be a problem for non-ordered categories like \"Color\" (Red, Green, Blue). In such cases, the model might misinterpret the numbers as a ranking. To avoid this, OneHot Encoding is a better option.\n",
        "\n",
        "Imbalanced Datasets\n",
        "Imbalanced datasets occur when one class has significantly more instances than the other(s), leading to biased models that favor the majority class.\n",
        "Common solutions include:\n",
        "Resampling:\n",
        "Oversampling: Increase the minority class.\n",
        "Undersampling: Reduce the majority class.\n",
        "Class Weights: Adjust weights to give more importance to the minority class.\n",
        "Ensemble Methods: Use techniques like Random Forest or XGBoost to handle imbalance better.\n",
        "These methods help improve model performance, especially in predicting the minority class.\n",
        "\n",
        "ROC Curve\n",
        "An ROC (Receiver Operating Characteristic) curve is a graphical representation used to evaluate the performance of a binary classification model. It plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold settings.\n",
        "True Positive Rate (TPR), also known as Sensitivity or Recall, is the proportion of actual positives correctly identified by the model.\n",
        "False Positive Rate (FPR) is the proportion of actual negatives incorrectly classified as positives.\n",
        "The ROC curve shows the tradeoff between sensitivity and specificity (1  FPR). A model with a curve closer to the topleft corner is considered better, as it indicates higher true positive rates and lower false positive rates. The area under the ROC curve (AUC) is often used as a summary metric; an AUC value closer to 1 indicates a better model.\n",
        "\n",
        "Precision and Recall\n",
        "Precision and recall are two important measures used to evaluate the performance of a model, especially in classification tasks.\n",
        "Precision refers to how many of the items identified as positive by the model are actually positive. In simple terms, it's about the accuracy of the positive predictions.\n",
        "Example: If a model predicts 10 items as positive, and 8 of them are actually positive, the precision is 8 10 = 80%.\n",
        "Recall refers to how many of the actual positive items were correctly identified by the model. It's about how good the model is at finding all the positive cases.\n",
        "Example: If there are 12 actual positive items, and the model identifies 8 of them, the recall is 8 12 = 67%.\n",
        "In summary:\n",
        "Precision = Correct positive predictions   Total positive predictions.\n",
        "Recall = Correct positive predictions   Total actual positives.\n",
        "Both are important for assessing how well a model is performing, especially when the data is imbalanced.\n",
        "\n",
        "F1 Score\n",
        "The F1 Score is a way to measure how well a model performs, especially when the data is unbalanced (for example, if one class is much larger than the other). It combines two important metrics: Precision and Recall.\n",
        "Precision tells us how many of the positive predictions made by the model were actually correct.\n",
        "Recall tells us how many of the actual positive cases were correctly identified by the model.\n",
        "The F1 Score is the harmonic mean of Precision and Recall, and it gives a balance between the two. A high F1 Score means the model is good at both identifying positive cases and minimizing false positives.\n",
        "Mathematically: F1 Score = 2 * (Precision * Recall)   (Precision + Recall)\n",
        "An F1 Score ranges from 0 to 1, where 1 is perfect performance.\n",
        "\n",
        "Confusion Matrix\n",
        "Confusion Matrix – Simple Explanation\n",
        "A Confusion Matrix is a table that helps us understand how well a classification model is performing. It compares the actual values with the predicted values to show where the model is making mistakes.\n",
        "For a binary classification problem, it has four key parts:\n",
        "True Positive (TP): The model correctly predicted a positive case.\n",
        "True Negative (TN): The model correctly predicted a negative case.\n",
        "False Positive (FP): The model incorrectly predicted positive (also called Type I Error).\n",
        "False Negative (FN): The model incorrectly predicted negative (also called Type II Error).\n",
        "The matrix looks like this:\n",
        "\n",
        "\n",
        "Predicted Positive\n",
        "Predicted Negative\n",
        "Actual Positive\n",
        "TP\n",
        "FN\n",
        "Actual Negative\n",
        "FP\n",
        "TN\n",
        "\n",
        "From this table, we can calculate important performance metrics like:\n",
        "Accuracy: How often the model is correct.\n",
        "Precision: How many of the predicted positives are actually correct.\n",
        "Recall: How many actual positives were correctly identified.\n",
        "F1 Score: A balance between Precision and Recall.\n",
        "This matrix is especially useful when the dataset is imbalanced, meaning one class is much more frequent than the other. It helps in making better decisions about model performance.\n",
        "\n",
        "\n",
        "Feature Selection\n",
        "Feature Selection is the process of selecting a subset of relevant features (variables) from the original dataset to improve the model’s performance and reduce complexity. It helps to avoid overfitting, improve accuracy, and reduce computational cost.\n",
        "There are three main techniques for feature selection:\n",
        "Filter Methods: These evaluate features independently of the model, using statistical tests like correlation, chisquare, or mutual information to rank features based on their relevance.\n",
        "Wrapper Methods: These use a specific machine learning model to evaluate feature subsets by training the model on different feature combinations. Methods like Recursive Feature Elimination (RFE) are common in this category.\n",
        "Embedded Methods: These perform feature selection during the model training process. Algorithms like Lasso (L1 regularization) and Decision Trees naturally perform feature selection by assigning importance to features.\n",
        "Feature selection helps improve model interpretability, speed, and generalization.\n",
        "\n",
        "Gradient Boosting\n",
        "Gradient Boosting is an ensemble learning method that builds a model by combining multiple weak learners (typically decision trees) to create a strong predictive model. It works by training models sequentially, with each new model trying to correct the errors (residuals) made by the previous models. The term \"gradient\" comes from the optimization technique used to minimize the loss function by updating the model in the direction of the negative gradient.\n",
        "Key steps in Gradient Boosting:\n",
        "Initialization: Start with a simple model (often predicting the mean or median).\n",
        "Iterative Process: For each iteration, a new decision tree is trained on the residual errors of the previous model.\n",
        "Update: The new model’s predictions are added to the existing model’s predictions, improving the overall accuracy.\n",
        "Gradient Boosting is known for its high performance in tasks like classification and regression, but it can be prone to overfitting if not properly tuned (e.g., using techniques like early stopping or limiting the depth of trees). Popular implementations include XGBoost, LightGBM, and CatBoost.\n",
        "\n",
        "AdaBoost\n",
        "AdaBoost (Adaptive Boosting) is an ensemble learning method that combines multiple weak learners (typically decision trees) to create a strong model. It works by sequentially training classifiers, each focusing on the errors made by the previous one. The key idea is to assign higher weights to misclassified data points so that subsequent models give more attention to those points.\n",
        "Key steps in AdaBoost:\n",
        "Initial Model: Train a weak classifier (e.g., decision tree) on the data.\n",
        "Weight Adjustment: Increase the weight of misclassified instances so the next classifier focuses more on them.\n",
        "Combine Weak Learners: The final model is a weighted combination of all the weak learners, where each model’s weight is based on its accuracy.\n",
        "AdaBoost is known for improving classification accuracy, particularly when the base model is weak. It is less prone to overfitting compared to other boosting methods and works well with binary classification tasks. However, it can be sensitive to noisy data.\n",
        "\n",
        "XGBoost\n",
        "XGBoost (Extreme Gradient Boosting) is an optimized and efficient implementation of gradient boosting, designed for speed and performance. It is widely used in machine learning competitions and realworld applications due to its high accuracy and scalability.\n",
        "Key features of XGBoost:\n",
        "Boosting Algorithm: Like gradient boosting, XGBoost builds an ensemble of decision trees sequentially, where each new tree corrects the errors of the previous one.\n",
        "Regularization: XGBoost includes L1 (Lasso) and L2 (Ridge) regularization to prevent overfitting, making it more robust than traditional gradient boosting.\n",
        "Parallelization: It can perform parallel processing during training, significantly speeding up the learning process.\n",
        "Handling Missing Data: XGBoost can handle missing values naturally, without the need for imputation.\n",
        "Tree Pruning: It uses a depthfirst approach for building trees and pruning them to avoid overfitting, using a technique called \"max depth\" to limit the tree growth.\n",
        "XGBoost is effective for classification, regression, and ranking tasks, and is known for its accuracy, speed, and ability to handle large datasets.\n",
        "\n",
        "LightGBM\n",
        "LightGBM (Light Gradient Boosting Machine) is a fast, efficient, and scalable gradient boosting framework, designed for large datasets and high performance. It is an alternative to XGBoost, focusing on speed and memory efficiency.\n",
        "Key features of LightGBM:\n",
        "Histogrambased Learning: LightGBM uses a histogrambased method to speed up the training process by discretizing continuous features into bins, reducing memory usage.\n",
        "Leafwise Growth: Unlike traditional levelwise tree growth, LightGBM grows trees leafwise, which often results in deeper, more complex trees and higher accuracy.\n",
        "Handling Large Datasets: It is optimized for handling large datasets, with efficient data handling and distributed computing capabilities.\n",
        "Categorical Feature Support: LightGBM can handle categorical features directly without the need for onehot encoding, which improves efficiency and model performance.\n",
        "Regularization: It supports both L1 (Lasso) and L2 (Ridge) regularization to prevent overfitting.\n",
        "LightGBM is widely used in machine learning tasks like classification, regression, and ranking, particularly for large datasets due to its speed, scalability, and performance.\n",
        "\n",
        "CatBoost\n",
        "CatBoost (Categorical Boosting) is a gradient boosting framework specifically designed to handle categorical features efficiently without the need for extensive preprocessing like onehot encoding. It is known for its high performance, ease of use, and effectiveness in handling heterogeneous data.\n",
        "Key features of CatBoost:\n",
        "Categorical Feature Handling: CatBoost automatically handles categorical features using a technique called ordered boosting, which prevents overfitting and ensures more accurate predictions.\n",
        "Efficient Training: CatBoost supports multithreading and GPU acceleration, making it faster for training on large datasets.\n",
        "Robust to Overfitting: It includes several techniques to combat overfitting, such as regularization and early stopping.\n",
        "Tree Symmetry: CatBoost builds symmetrical trees, which helps in reducing overfitting and improving generalization.\n",
        "Interpretability: CatBoost provides tools for model interpretation, allowing users to understand feature importance and decisionmaking processes.\n",
        "CatBoost is widely used for classification, regression, and ranking tasks and is particularly effective for datasets with many categorical features. Its ease of use, speed, and accuracy make it a popular choice in machine learning applications.\n",
        "\n",
        "Mean Squared Error (MSE)\n",
        "Mean Squared Error (MSE) is a way to measure how far off predictions are from the actual results. It calculates the average of the squares of the differences between predicted values and actual values.\n",
        "Here's how it works:\n",
        "Subtract the predicted value from the actual value (this gives you the error).\n",
        "Square the error (so it's always positive).\n",
        "Take the average of all the squared errors.\n",
        "A lower MSE means the predictions are closer to the actual values, and a higher MSE means they are further off. It’s commonly used to evaluate models in regression tasks.\n",
        "\n",
        "Root Mean Squared Error (RMSE)\n",
        "Root Mean Squared Error (RMSE) is a way to measure how far off predictions are from the actual values.\n",
        "In simple terms:\n",
        "It takes the difference between the predicted values and the actual values.\n",
        "It squares these differences (to avoid negative values).\n",
        "It then finds the average of these squared differences.\n",
        "Finally, it takes the square root of that average to get the RMSE.\n",
        "The lower the RMSE, the better the model's predictions are. It tells you how much error is in your model's predictions in the same units as the data.\n",
        "\n",
        "Mean Absolute Error (MAE)\n",
        "Mean Absolute Error (MAE) is a way to measure how wrong predictions are compared to actual values. It calculates the average difference between the predicted values and the actual values, ignoring whether the difference is positive or negative.\n",
        "In simple terms, it tells you, on average, how far off your predictions are. For example, if your MAE is 5, it means your predictions are off by 5 units on average.\n",
        "Lower MAE means your predictions are closer to the actual values, so it's better.\n",
        "\n",
        "Heteroscedasticity\n",
        "Heteroscedasticity occurs when the variance of residuals (errors) in a regression model is not constant across all levels of the independent variable(s). This violates the assumption of homoscedasticity, where residuals should have constant variance.\n",
        "Detection:\n",
        "Residual Plots: A pattern in the spread of residuals indicates heteroscedasticity.\n",
        "BreuschPagan and White Tests: Statistical tests to detect it.\n",
        "Solutions:\n",
        "Transformation: Apply transformations (e.g., log) to stabilize variance.\n",
        "Weighted Least Squares (WLS): Adjust weights for different observations.\n",
        "Robust Standard Errors: Adjust standard errors to account for heteroscedasticity.\n",
        "Fixing it ensures better model performance and reliable statistical inference.\n",
        "\n",
        "Multicollinearity\n",
        "Multicollinearity occurs when two or more independent variables in a regression model are highly correlated, meaning they share similar information. This can cause instability in the coefficient estimates and make it difficult to assess the individual impact of each predictor.\n",
        "Detection:\n",
        "Correlation Matrix: High correlation between variables indicates multicollinearity.\n",
        "Variance Inflation Factor (VIF): A VIF above 10 suggests high multicollinearity.\n",
        "Solutions:\n",
        "Remove Variables: Drop one of the correlated variables.\n",
        "Combine Variables: Use techniques like Principal Component Analysis (PCA) to combine correlated features.\n",
        "Regularization: Apply Lasso or Ridge regression to penalize correlated features.\n",
        "Addressing multicollinearity improves model stability and interpretability.\n",
        "\n",
        "VIF (Variance Inflation Factor)\n",
        "Variance Inflation Factor (VIF) is a measure used in statistics to check if independent variables (predictors) in a regression model are highly correlated with each other. It helps identify multicollinearity, which can make it hard to determine the effect of each predictor.\n",
        "In simple terms:\n",
        "Low VIF (close to 1): The variable is not strongly correlated with others, so it's fine to include in the model.\n",
        "High VIF (e.g., above 5 or 10): The variable is highly correlated with others, which might distort the model's results.\n",
        "When VIF is too high, you might consider removing or combining variables to improve the model.\n",
        "\n",
        "Outlier Detection\n",
        "Outlier detection is the process of identifying data points that are significantly different from most of the other data points in a dataset. These unusual values, called \"outliers,\" may be caused by errors, rare events, or unique conditions. Detecting outliers is important because they can affect the results of analysis or provide valuable insights.\n",
        "For example, in a dataset of people's heights, if most heights are around 5 to 6 feet but one is 9 feet, that 9-foot value is likely an outlier.\n",
        "\n",
        "CrossEntropy Loss\n",
        "CrossEntropy Loss is a way to measure how well a machine learning model predicts a set of labels. It's commonly used for classification tasks, like determining which category an input belongs to.\n",
        "In simple terms:\n",
        "It compares the model's predicted probabilities for each class to the true class label (which is usually represented as 1 for the correct class and 0 for the others).\n",
        "The closer the predicted probability for the correct class is to 1, the smaller the loss. If the model predicts the wrong class with high confidence, the loss becomes large.\n",
        "The goal is to minimize this loss so the model becomes better at predicting the correct class.\n",
        "It’s like a penalty system: the further the prediction is from the true label, the higher the penalty.\n",
        "\n",
        "Model Interpretability Techniques\n",
        "Model Interpretability Techniques help to understand, explain, and trust machine learning models, especially complex ones like deep learning or ensemble models.\n",
        "Key Techniques:\n",
        "Feature Importance: Identifies which features contribute most to model predictions (e.g., in decision trees, random forests, XGBoost).\n",
        "SHAP (Shapley Additive Explanations): Provides a unified measure of feature importance by calculating each feature’s contribution to a specific prediction, based on cooperative game theory.\n",
        "LIME (Local Interpretable ModelAgnostic Explanations): Creates interpretable models (e.g., linear regression) for individual predictions by approximating the blackbox model locally.\n",
        "Partial Dependence Plots (PDPs): Shows the relationship between a feature and the predicted outcome, holding other features constant.\n",
        "Permutation Feature Importance: Measures the effect of shuffling a feature on model performance, indicating its importance.\n",
        "ICE (Individual Conditional Expectation) Plots: Visualizes the effect of a feature on the predicted outcome for each instance, showing variations across data points.\n",
        "These techniques enhance transparency and trust in machine learning models, ensuring better decisionmaking and ethical usage.\n",
        "\n",
        "Gradient Descent\n",
        "Gradient Descent is a method used to find the best solution to a problem by making small changes step by step.\n",
        "Think of it like walking down a hill to reach the lowest point. You start at some random spot and look around to see which direction is the steepest downward slope. Then you take a small step in that direction. You repeat this process until you can't go any lower.\n",
        "In math or machine learning, it's used to minimize errors in a model by adjusting values (parameters) to make predictions more accurate. The size of each step is controlled by a factor called the \"learning rate.\" If the steps are too big, you might miss the lowest point; if they're too small, it takes a long time to get there.\n",
        "\n",
        "Linear Regression\n",
        "Linear regression is a basic statistical method used to understand the relationship between two variables. It predicts one variable (the dependent variable) based on the value of another variable (the independent variable).\n",
        "Imagine you want to predict how much a person will earn based on the number of years they’ve worked. Linear regression creates a straight line that best fits the data points you have, showing the trend or pattern. This line helps you make predictions for future cases.\n",
        "In short:\n",
        "It finds the \"best-fit\" straight line through data points.\n",
        "The formula for the line is: y = mx + b (where y is the dependent variable, x is the independent variable, m is the slope, and b is the intercept).\n",
        "It’s commonly used for making predictions and identifying trends.\n",
        "\n",
        "Feature Scaling\n",
        "Feature scaling is a method used in data preprocessing to make sure that all the features (or variables) in your data have the same scale.\n",
        "For example, if one feature measures weight in kilograms (like 50, 60, 70) and another measures height in centimeters (like 150, 160, 170), their ranges are very different. This can cause problems in some machine learning algorithms that are sensitive to differences in scale, like gradient descent or distance-based methods (e.g., k-Nearest Neighbors).\n",
        "Two common techniques for feature scaling are:\n",
        "Normalization: This scales the data to fit within a specific range, like 0 to 1. Formula: (x - min)   (max - min)\n",
        "Standardization: This scales the data so that it has a mean of 0 and a standard deviation of 1. Formula: (x - mean)   standard deviation\n",
        "In short, feature scaling ensures that no single feature dominates others because of its larger range.\n",
        " \"\"\""
      ],
      "metadata": {
        "id": "rDzRhjyKa8zX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Result\n",
        "text_to_speech(name, text)"
      ],
      "metadata": {
        "id": "M5fw0jMKvoBJ",
        "outputId": "15b9830c-9d57-4226-c3f2-db1671df02a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MP3 file 'Technical Fluency part-1.mp3' has been generated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OciIIzGea7Vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR REPEATED TASK"
      ],
      "metadata": {
        "id": "gVenS8qNKFGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import edge_tts\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "\n",
        "# Fix asyncio issue in Colab/Jupyter Notebook\n",
        "nest_asyncio.apply()\n",
        "\n",
        "async def generate_speech(text, file_name, voice=\"en-US-GuyNeural\", repeat_count=1):\n",
        "    \"\"\"Generates an MP3 file with repeated text using Edge TTS.\"\"\"\n",
        "    repeated_text = (text + \" \") * repeat_count  # Repeat text as per user input\n",
        "    tts = edge_tts.Communicate(repeated_text.strip(), voice)\n",
        "    await tts.save(file_name)\n",
        "    print(f\"MP3 file '{file_name}' has been generated successfully!\")\n",
        "\n",
        "def text_to_speech(file_name, text, repeat_count, voice=\"en-US-GuyNeural\"):\n",
        "    \"\"\"Runs the async function in a synchronous way.\"\"\"\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(generate_speech(text, file_name, voice, repeat_count))\n",
        "\n",
        "# Example Usage\n",
        "repeat = int(input(\"Enter the number of times you want to repeat the text: \"))  # User input\n",
        "text_to_speech(\"output.mp3\", \"Hello, this is an AI-generated voice!\", repeat)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmQR0hqd9HJJ",
        "outputId": "db1be7b8-4065-4927-d836-3c7e25947b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of times you want to repeat the text: 5\n",
            "MP3 file 'output.mp3' has been generated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repeat = 5\n",
        "name = \"1. Introduce Yourself - AlmaX.mp3\"\n",
        "text = \"\"\" Introduce Yourself - AlmaX\n",
        "\n",
        "Hello everyone, my name is Bharat Gaur, and I am a dedicated Data Scientist from Ghaziabad, Uttar Pradesh. My expertise lies in machine learning, statistical analysis, and extracting meaningful insights from complex datasets to drive data-driven decision-making.\n",
        "\n",
        "Academic Background:\n",
        "I have a strong educational foundation in Data Science and Artificial Intelligence. I completed my Master’s in Data Science & AI from IIT Guwahati (in collaboration with AlmaBetter). Before that, I pursued a Bachelor’s degree in Mechanical Engineering from Aligarh College of Engineering & Technology.\n",
        "\n",
        "Technical Skills:\n",
        "I have hands-on experience with multiple programming languages and tools essential for Data Science:\n",
        "\n",
        "Programming Languages: Python and SQL, along with libraries like NumPy and Pandas for data manipulation, and scikit-learn for machine learning.\n",
        "\n",
        "Data Analysis & Visualization Tools: I am skilled in Advanced Excel, Tableau, and Power BI, which help in creating insightful reports and dashboards.\n",
        "\n",
        "Specialized Frameworks: My expertise extends to advanced areas like Machine Learning, Artificial Intelligence, Natural Language Processing (NLP), Deep Learning,\n",
        "Computer Vision, and MLOps, enabling me to work on cutting-edge AI solutions.\n",
        "\n",
        "Professional Experience:\n",
        "I have diverse work experience across different industries, contributing to various aspects of data analysis, quality control, and supply chain optimization.\n",
        "Currently, I am working as a Data Analyst at Moozza Footwear LLP (since 2024), where I focus on optimizing inventory management and improving operational efficiency through data-driven strategies.\n",
        "Previously, I worked as a QA QC Engineer at ARC Infratech (2020–2024), ensuring quality compliance and process optimization.\n",
        "Before that, I was a Supply Chain Engineer at Shaurya Plastic Molding Works (2018–2020), where I played a key role in improving production logistics and streamlining operations.\n",
        "Certifications & Achievements:\n",
        "To further strengthen my expertise, I have earned multiple certifications and recognitions:\n",
        "Full Stack Data Science Certification (2023–2024) from AlmaBetter, which provided in-depth knowledge of data science concepts and practical applications.\n",
        "Gold Badges on HackerRank in SQL and Python, demonstrating my proficiency in problem-solving and technical skills.\n",
        "Hobbies & Interests:\n",
        "Beyond my professional work, I am passionate about exploring advancements in Artificial Intelligence, staying updated with the latest industry trends, and engaging in fitness and sports to maintain an active lifestyle.\n",
        "This was a brief introduction about me. Thank you for listening!\n",
        "\"\"\"\n",
        "text_to_speech(name, text , repeat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT_VebLJ9HHE",
        "outputId": "3f69e97b-8962-44c0-9bf5-d1bd5d1b4529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MP3 file '1. Introduce Yourself - AlmaX.mp3' has been generated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V1lHIYEO9HCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "juQmsTOO9HBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KGRzsbFI9G9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HpFSIYXn9G72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a_DZYgJw9G0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "smYE43xV9Goz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wDoxgclz9EvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hiSA7Ydh9ErD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nDqq8GLN9EpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aD2ZLSl49ElK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t2lPmbpb9EjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W890f3HW9Efu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7NCHXMup9Edj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vhi1YaMm9EZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "appNg7JV9EYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RgL5lv3V9ET0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9z-Wg9_z9ESs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kouoc_1z9EOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E1ZlY-EI9EM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "br4PM5sy9EDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y imagemagick"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oziHdhqZfh_1",
        "outputId": "4caa12b6-afb8-4bb1-81cd-dda447dccd85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,315 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,230 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,659 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,609 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,526 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,911 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,682 kB]\n",
            "Fetched 21.3 MB in 4s (5,561 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "imagemagick is already the newest version (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/none/read|write/' /etc/ImageMagick-6/policy.xml"
      ],
      "metadata": {
        "id": "ZKfkHylJiCk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kill -9 -1"
      ],
      "metadata": {
        "id": "IvmJLcj6iGxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages (Run this only once)\n",
        "!apt-get update\n",
        "!apt-get install -y imagemagick\n",
        "!sed -i 's/none/read|write/' /etc/ImageMagick-6/policy.xml\n",
        "!pip install edge-tts moviepy\n",
        "\n",
        "import edge_tts\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "from moviepy.editor import *\n",
        "\n",
        "# Fix asyncio issue in Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Input text for TTS and video\n",
        "text = \"\"\"This is a test. Your generated video will display text sentence by sentence while playing audio.\"\"\"\n",
        "audio_file = \"output_audio.mp3\"\n",
        "video_file = \"final_video.mp4\"\n",
        "\n",
        "# Convert text to speech with a male voice\n",
        "async def text_to_speech(text, audio_file):\n",
        "    voice = \"en-US-GuyNeural\"  # Deep & attractive male voice\n",
        "    tts = edge_tts.Communicate(text, voice)\n",
        "    await tts.save(audio_file)\n",
        "\n",
        "loop = asyncio.get_event_loop()\n",
        "loop.run_until_complete(text_to_speech(text, audio_file))\n",
        "\n",
        "# Function to create video with text overlay\n",
        "def create_video_with_text(audio_file, text, video_file, resolution=(1280, 720), fps=30):\n",
        "    # Load audio file\n",
        "    audio = AudioFileClip(audio_file)\n",
        "    duration = audio.duration\n",
        "\n",
        "    # Split text into sentences\n",
        "    sentences = text.split(\". \")\n",
        "\n",
        "    # Create text clips (sentence-by-sentence animation)\n",
        "    clips = []\n",
        "    start_time = 0\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip()\n",
        "        if sentence:\n",
        "            txt_clip = TextClip(sentence, fontsize=50, color='white', size=resolution, method='caption', font=\"Liberation-Sans\")\n",
        "            txt_clip = txt_clip.set_position(\"center\").set_duration(3).set_start(start_time)\n",
        "            clips.append(txt_clip)\n",
        "            start_time += 3\n",
        "\n",
        "    # Create blank background\n",
        "    bg_clip = ColorClip(resolution, color=(30, 30, 30), duration=duration)\n",
        "\n",
        "    # Overlay text on background\n",
        "    final_video = CompositeVideoClip([bg_clip] + clips)\n",
        "    final_video = final_video.set_audio(audio)\n",
        "\n",
        "    # Write final video\n",
        "    final_video.write_videofile(video_file, fps=fps, codec=\"libx264\", threads=4, preset=\"ultrafast\")\n",
        "\n",
        "# Generate final video\n",
        "create_video_with_text(audio_file, text, video_file)\n",
        "\n",
        "# Display final output\n",
        "from google.colab import files\n",
        "files.download(video_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xxGCZyJMiKMa",
        "outputId": "8911d2ff-3d01-49fd-9931-b1216a34286c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Waiting for headers] [1 InRelease 14.2 kB/129 kB 11%] [Connecting to cloud.r-project.org (65.9.8\r                                                                                                    \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [1 InRelease 129 kB/129 kB 100%] [Connected to cloud.r-project.org (65.9.86.109)] [Connecting to \r                                                                                                    \rGet:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r                                                                                                    \rGet:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r                                                                                                    \rGet:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [3 InRelease 128 kB/128 kB 100%] [Connecting to r2u.stat.illinois.edu (192.17.190.167)] [Waiting \r0% [Waiting for headers] [Connecting to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers\r                                                                                                    \rGet:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "\r0% [6 InRelease 38.8 kB/127 kB 30%] [Connecting to r2u.stat.illinois.edu (192.17.190.167)] [Waiting \r                                                                                                    \r0% [Connecting to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers]\r                                                                               \rHit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "\r                                                                               \r0% [Connected to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers]\r                                                                              \rHit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,230 kB]\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,609 kB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,315 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,526 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,911 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,659 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,682 kB]\n",
            "Fetched 21.3 MB in 5s (4,137 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-droid-fallback fonts-noto-mono fonts-urw-base35 ghostscript gsfonts imagemagick-6-common\n",
            "  imagemagick-6.q16 libdjvulibre-text libdjvulibre21 libfftw3-double3 libgs9 libgs9-common libidn12\n",
            "  libijs-0.35 libjbig2dec0 libjxr-tools libjxr0 liblqr-1-0 libmagickcore-6.q16-6\n",
            "  libmagickcore-6.q16-6-extra libmagickwand-6.q16-6 libnetpbm10 libwmflite-0.2-7 netpbm\n",
            "  poppler-data\n",
            "Suggested packages:\n",
            "  fonts-noto fonts-freefont-otf | fonts-freefont-ttf fonts-texgyre ghostscript-x imagemagick-doc\n",
            "  autotrace cups-bsd | lpr | lprng enscript gimp gnuplot grads hp2xx html2ps libwmf-bin mplayer\n",
            "  povray radiance sane-utils texlive-base-bin transfig ufraw-batch libfftw3-bin libfftw3-dev\n",
            "  inkscape poppler-utils fonts-japanese-mincho | fonts-ipafont-mincho fonts-japanese-gothic\n",
            "  | fonts-ipafont-gothic fonts-arphic-ukai fonts-arphic-uming fonts-nanum\n",
            "The following NEW packages will be installed:\n",
            "  fonts-droid-fallback fonts-noto-mono fonts-urw-base35 ghostscript gsfonts imagemagick\n",
            "  imagemagick-6-common imagemagick-6.q16 libdjvulibre-text libdjvulibre21 libfftw3-double3 libgs9\n",
            "  libgs9-common libidn12 libijs-0.35 libjbig2dec0 libjxr-tools libjxr0 liblqr-1-0\n",
            "  libmagickcore-6.q16-6 libmagickcore-6.q16-6-extra libmagickwand-6.q16-6 libnetpbm10\n",
            "  libwmflite-0.2-7 netpbm poppler-data\n",
            "0 upgraded, 26 newly installed, 0 to remove and 23 not upgraded.\n",
            "Need to get 25.1 MB of archives.\n",
            "After this operation, 87.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1build1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfftw3-double3 amd64 3.3.8-2ubuntu8 [770 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 liblqr-1-0 amd64 0.4.2-2.1 [27.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 imagemagick-6-common all 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [64.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmagickcore-6.q16-6 amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [1,795 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmagickwand-6.q16-6 amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [328 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2,171 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-urw-base35 all 20200910-1 [6,367 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9-common all 9.55.0~dfsg1-0ubuntu5.10 [752 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libidn12 amd64 1.38-4ubuntu1 [60.0 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libijs-0.35 amd64 0.35-15build2 [16.5 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjbig2dec0 amd64 0.19-3build2 [64.7 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9 amd64 9.55.0~dfsg1-0ubuntu5.10 [5,031 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ghostscript amd64 9.55.0~dfsg1-0ubuntu5.10 [49.4 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 gsfonts all 1:8.11+urwcyr1.0.7~pre44-4.5 [3,120 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 imagemagick-6.q16 amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [224 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 imagemagick amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [14.6 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdjvulibre-text all 3.5.28-2build2 [50.9 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdjvulibre21 amd64 3.5.28-2build2 [624 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjxr0 amd64 1.2~git20170615.f752187-5 [174 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjxr-tools amd64 1.2~git20170615.f752187-5 [16.0 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwmflite-0.2-7 amd64 0.2.12-5ubuntu1 [68.9 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmagickcore-6.q16-6-extra amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [70.1 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libnetpbm10 amd64 2:10.0-15.4 [59.1 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/universe amd64 netpbm amd64 2:10.0-15.4 [1,007 kB]\n",
            "Fetched 25.1 MB in 0s (56.0 MB/s)\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 124926 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Selecting previously unselected package libfftw3-double3:amd64.\n",
            "Preparing to unpack .../01-libfftw3-double3_3.3.8-2ubuntu8_amd64.deb ...\n",
            "Unpacking libfftw3-double3:amd64 (3.3.8-2ubuntu8) ...\n",
            "Selecting previously unselected package liblqr-1-0:amd64.\n",
            "Preparing to unpack .../02-liblqr-1-0_0.4.2-2.1_amd64.deb ...\n",
            "Unpacking liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Selecting previously unselected package imagemagick-6-common.\n",
            "Preparing to unpack .../03-imagemagick-6-common_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_all.deb ...\n",
            "Unpacking imagemagick-6-common (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-6:amd64.\n",
            "Preparing to unpack .../04-libmagickcore-6.q16-6_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libmagickwand-6.q16-6:amd64.\n",
            "Preparing to unpack .../05-libmagickwand-6.q16-6_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking libmagickwand-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../06-poppler-data_0.4.11-1_all.deb ...\n",
            "Unpacking poppler-data (0.4.11-1) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../07-fonts-noto-mono_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-mono (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-urw-base35.\n",
            "Preparing to unpack .../08-fonts-urw-base35_20200910-1_all.deb ...\n",
            "Unpacking fonts-urw-base35 (20200910-1) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../09-libgs9-common_9.55.0~dfsg1-0ubuntu5.10_all.deb ...\n",
            "Unpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Selecting previously unselected package libidn12:amd64.\n",
            "Preparing to unpack .../10-libidn12_1.38-4ubuntu1_amd64.deb ...\n",
            "Unpacking libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../11-libijs-0.35_0.35-15build2_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../12-libjbig2dec0_0.19-3build2_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../13-libgs9_9.55.0~dfsg1-0ubuntu5.10_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../14-ghostscript_9.55.0~dfsg1-0ubuntu5.10_amd64.deb ...\n",
            "Unpacking ghostscript (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Selecting previously unselected package gsfonts.\n",
            "Preparing to unpack .../15-gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.5_all.deb ...\n",
            "Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.5) ...\n",
            "Selecting previously unselected package imagemagick-6.q16.\n",
            "Preparing to unpack .../16-imagemagick-6.q16_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking imagemagick-6.q16 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package imagemagick.\n",
            "Preparing to unpack .../17-imagemagick_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking imagemagick (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libdjvulibre-text.\n",
            "Preparing to unpack .../18-libdjvulibre-text_3.5.28-2build2_all.deb ...\n",
            "Unpacking libdjvulibre-text (3.5.28-2build2) ...\n",
            "Selecting previously unselected package libdjvulibre21:amd64.\n",
            "Preparing to unpack .../19-libdjvulibre21_3.5.28-2build2_amd64.deb ...\n",
            "Unpacking libdjvulibre21:amd64 (3.5.28-2build2) ...\n",
            "Selecting previously unselected package libjxr0:amd64.\n",
            "Preparing to unpack .../20-libjxr0_1.2~git20170615.f752187-5_amd64.deb ...\n",
            "Unpacking libjxr0:amd64 (1.2~git20170615.f752187-5) ...\n",
            "Selecting previously unselected package libjxr-tools.\n",
            "Preparing to unpack .../21-libjxr-tools_1.2~git20170615.f752187-5_amd64.deb ...\n",
            "Unpacking libjxr-tools (1.2~git20170615.f752187-5) ...\n",
            "Selecting previously unselected package libwmflite-0.2-7:amd64.\n",
            "Preparing to unpack .../22-libwmflite-0.2-7_0.2.12-5ubuntu1_amd64.deb ...\n",
            "Unpacking libwmflite-0.2-7:amd64 (0.2.12-5ubuntu1) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-6-extra:amd64.\n",
            "Preparing to unpack .../23-libmagickcore-6.q16-6-extra_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-6-extra:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libnetpbm10.\n",
            "Preparing to unpack .../24-libnetpbm10_2%3a10.0-15.4_amd64.deb ...\n",
            "Unpacking libnetpbm10 (2:10.0-15.4) ...\n",
            "Selecting previously unselected package netpbm.\n",
            "Preparing to unpack .../25-netpbm_2%3a10.0-15.4_amd64.deb ...\n",
            "Unpacking netpbm (2:10.0-15.4) ...\n",
            "Setting up imagemagick-6-common (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up fonts-noto-mono (20201225-1build1) ...\n",
            "Setting up libwmflite-0.2-7:amd64 (0.2.12-5ubuntu1) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Setting up libjxr0:amd64 (1.2~git20170615.f752187-5) ...\n",
            "Setting up libnetpbm10 (2:10.0-15.4) ...\n",
            "Setting up fonts-urw-base35 (20200910-1) ...\n",
            "Setting up poppler-data (0.4.11-1) ...\n",
            "Setting up libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.5) ...\n",
            "Setting up libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Setting up netpbm (2:10.0-15.4) ...\n",
            "Setting up libfftw3-double3:amd64 (3.3.8-2ubuntu8) ...\n",
            "Setting up liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Setting up libdjvulibre-text (3.5.28-2build2) ...\n",
            "Setting up libgs9-common (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Setting up libjxr-tools (1.2~git20170615.f752187-5) ...\n",
            "Setting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Setting up libdjvulibre21:amd64 (3.5.28-2build2) ...\n",
            "Setting up ghostscript (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Setting up libmagickcore-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up libmagickwand-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up libmagickcore-6.q16-6-extra:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up imagemagick-6.q16 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare (compare) in auto mode\n",
            "update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare-im6 (compare-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate (animate) in auto mode\n",
            "update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate-im6 (animate-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert (convert) in auto mode\n",
            "update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert-im6 (convert-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite (composite) in auto mode\n",
            "update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite-im6 (composite-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure (conjure) in auto mode\n",
            "update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure-im6 (conjure-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import (import) in auto mode\n",
            "update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import-im6 (import-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify (identify) in auto mode\n",
            "update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify-im6 (identify-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream (stream) in auto mode\n",
            "update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream-im6 (stream-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display (display) in auto mode\n",
            "update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display-im6 (display-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage (montage) in auto mode\n",
            "update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage-im6 (montage-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify (mogrify) in auto mode\n",
            "update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify-im6 (mogrify-im6) in auto mode\n",
            "Setting up imagemagick (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Collecting edge-tts\n",
            "  Downloading edge_tts-7.0.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (3.11.12)\n",
            "Requirement already satisfied: certifi>=2023.11.17 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (2025.1.31)\n",
            "Collecting srt<4.0.0,>=3.4.1 (from edge-tts)\n",
            "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate<1.0.0,>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (4.12.2)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.18.3)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Downloading edge_tts-7.0.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: srt\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22428 sha256=3200b7dc5b1f0cc7dc49fd140e476658b4d0934b0f67eeedc407712060e49a81\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/43/f1/23ee9119497fcb57d9f7046fbf34c6d9027c46a1fa7824cf08\n",
            "Successfully built srt\n",
            "Installing collected packages: srt, edge-tts\n",
            "Successfully installed edge-tts-7.0.0 srt-3.5.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video final_video.mp4.\n",
            "MoviePy - Writing audio in final_videoTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                              "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready final_video.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_97b930d2-a4fb-426c-948a-5bcfb5ae88e6\", \"final_video.mp4\", 172181)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages (Run this only once)\n",
        "!apt-get update\n",
        "!apt-get install -y imagemagick\n",
        "!sed -i 's/none/read|write/' /etc/ImageMagick-6/policy.xml\n",
        "!pip install edge-tts moviepy\n",
        "\n",
        "import edge_tts\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "from moviepy.editor import *\n",
        "from google.colab import files\n",
        "\n",
        "# Fix asyncio issue in Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# 📌 Step 1: Input Text\n",
        "text = input(\"Enter the text for your video: \")\n",
        "\n",
        "# Output file names\n",
        "audio_file = \"output_audio.mp3\"\n",
        "video_file = \"final_video.mp4\"\n",
        "\n",
        "# 📌 Step 2: Convert text to speech\n",
        "async def text_to_speech(text, audio_file):\n",
        "    voice = \"en-US-GuyNeural\"  # Male voice\n",
        "    tts = edge_tts.Communicate(text, voice)\n",
        "    await tts.save(audio_file)\n",
        "\n",
        "loop = asyncio.get_event_loop()\n",
        "loop.run_until_complete(text_to_speech(text, audio_file))\n",
        "\n",
        "# 📌 Step 3: Create video with text overlay\n",
        "def create_video_with_text(audio_file, text, video_file, resolution=(1280, 720), fps=30):\n",
        "    # Load audio file\n",
        "    audio = AudioFileClip(audio_file)\n",
        "    duration = audio.duration\n",
        "\n",
        "    # Split text into sentences\n",
        "    sentences = text.split(\". \")\n",
        "\n",
        "    # Create text clips (sentence-by-sentence animation)\n",
        "    clips = []\n",
        "    start_time = 0\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip()\n",
        "        if sentence:\n",
        "            txt_clip = TextClip(sentence, fontsize=50, color='white', size=resolution, method='caption', font=\"Liberation-Sans\")\n",
        "            txt_clip = txt_clip.set_position(\"center\").set_duration(3).set_start(start_time)\n",
        "            clips.append(txt_clip)\n",
        "            start_time += 3\n",
        "\n",
        "    # Create blank background\n",
        "    bg_clip = ColorClip(resolution, color=(30, 30, 30), duration=duration)\n",
        "\n",
        "    # Overlay text on background\n",
        "    final_video = CompositeVideoClip([bg_clip] + clips)\n",
        "    final_video = final_video.set_audio(audio)\n",
        "\n",
        "    # Write final video\n",
        "    final_video.write_videofile(video_file, fps=fps, codec=\"libx264\", threads=4, preset=\"ultrafast\")\n",
        "\n",
        "# Generate final video\n",
        "create_video_with_text(audio_file, text, video_file)\n",
        "\n",
        "# 📌 Step 4: Download final video\n",
        "files.download(video_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "id": "CcFuWB5jif4h",
        "outputId": "745ff138-0473-4ebd-94c1-4db86f9472fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.81)] [Connected to cloud.r-pr\r                                                                                                    \rHit:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "\r                                                                                                    \rHit:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (91.189.91.81)] [Connected to cloud.r-project.org (65.9.86.118\r                                                                                                    \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (91.189.91.81)] [Connected to cloud.r-project.org (65.9.86.118\r                                                                                                    \rHit:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Connecting to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers\r                                                                                                    \rHit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers]\r                                                                                                    \rHit:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers]\r                                                                                                    \rHit:8 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "imagemagick is already the newest version (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n",
            "Requirement already satisfied: edge-tts in /usr/local/lib/python3.11/dist-packages (7.0.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (3.11.12)\n",
            "Requirement already satisfied: certifi>=2023.11.17 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (2025.1.31)\n",
            "Requirement already satisfied: srt<4.0.0,>=3.4.1 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (3.5.3)\n",
            "Requirement already satisfied: tabulate<1.0.0,>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (4.12.2)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.18.3)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Enter the text for your video: Introduce Yourself - AlmaX Hello everyone, my name is Bharat Gaur, and I am a dedicated Data Scientist from Ghaziabad, Uttar Pradesh. My expertise lies in machine learning, statistical analysis, and extracting meaningful insights from complex datasets to drive data-driven decision-making. Academic Background: I have a strong educational foundation in Data Science and Artificial Intelligence. I completed my Master’s in Data Science & AI from IIT Guwahati (in collaboration with AlmaBetter). Before that, I pursued a Bachelor’s degree in Mechanical Engineering from Aligarh College of Engineering & Technology. Technical Skills: I have hands-on experience with multiple programming languages and tools essential for Data Science: Programming Languages: Python and SQL, along with libraries like NumPy and Pandas for data manipulation, and scikit-learn for machine learning. Data Analysis & Visualization Tools: I am skilled in Advanced Excel, Tableau, and Power BI, which help in creating insightful reports and dashboards. Specialized Frameworks: My expertise extends to advanced areas like Machine Learning, Artificial Intelligence, Natural Language Processing (NLP), Deep Learning, Computer Vision, and MLOps, enabling me to work on cutting-edge AI solutions. Professional Experience: I have diverse work experience across different industries, contributing to various aspects of data analysis, quality control, and supply chain optimization. Currently, I am working as a Data Analyst at Moozza Footwear LLP (since 2024), where I focus on optimizing inventory management and improving operational efficiency through data-driven strategies. Previously, I worked as a QA/QC Engineer at ARC Infratech (2020–2024), ensuring quality compliance and process optimization. Before that, I was a Supply Chain Engineer at Shaurya Plastic Molding Works (2018–2020), where I played a key role in improving production logistics and streamlining operations. Certifications & Achievements: To further strengthen my expertise, I have earned multiple certifications and recognitions: Full Stack Data Science Certification (2023–2024) from AlmaBetter, which provided in-depth knowledge of data science concepts and practical applications. Gold Badges on HackerRank in SQL and Python, demonstrating my proficiency in problem-solving and technical skills. Hobbies & Interests: Beyond my professional work, I am passionate about exploring advancements in Artificial Intelligence, staying updated with the latest industry trends, and engaging in fitness and sports to maintain an active lifestyle. This was a brief introduction about me. Thank you for listening!\n",
            "Moviepy - Building video final_video.mp4.\n",
            "MoviePy - Writing audio in final_videoTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready final_video.mp4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_03d01e61-df8f-4428-be87-bf1bf3569024\", \"final_video.mp4\", 4393717)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages (Run this only once)\n",
        "!apt-get update\n",
        "!apt-get install -y imagemagick\n",
        "!sed -i 's/none/read|write/' /etc/ImageMagick-6/policy.xml\n",
        "!pip install edge-tts moviepy\n",
        "\n",
        "import edge_tts\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "from moviepy.editor import *\n",
        "from google.colab import files\n",
        "import textwrap\n",
        "\n",
        "# Fix asyncio issue in Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# 📌 Step 1: Input Text\n",
        "text = input(\"Enter the text for your video: \")\n",
        "\n",
        "# Output file names\n",
        "audio_file = \"output_audio.mp3\"\n",
        "video_file = \"final_video.mp4\"\n",
        "\n",
        "# 📌 Step 2: Convert text to speech\n",
        "async def text_to_speech(text, audio_file):\n",
        "    voice = \"en-US-GuyNeural\"  # Male voice\n",
        "    tts = edge_tts.Communicate(text, voice)\n",
        "    await tts.save(audio_file)\n",
        "\n",
        "loop = asyncio.get_event_loop()\n",
        "loop.run_until_complete(text_to_speech(text, audio_file))\n",
        "\n",
        "# 📌 Step 3: Create video with text overlay (Proper Sync)\n",
        "def create_video_with_text(audio_file, text, video_file, resolution=(1280, 720), fps=30):\n",
        "    # Load audio file\n",
        "    audio = AudioFileClip(audio_file)\n",
        "    duration = audio.duration  # Total duration of audio\n",
        "\n",
        "    # Split text into sentences\n",
        "    sentences = text.split(\". \")\n",
        "    num_sentences = len(sentences)\n",
        "\n",
        "    # Calculate equal display time per sentence\n",
        "    sentence_duration = duration / num_sentences\n",
        "\n",
        "    # Create text clips (sentence-by-sentence animation)\n",
        "    clips = []\n",
        "    start_time = 0\n",
        "    for sentence in sentences:\n",
        "        wrapped_text = \"\\n\".join(textwrap.wrap(sentence, width=40))  # Wrap long text\n",
        "        if wrapped_text:\n",
        "            txt_clip = TextClip(\n",
        "                wrapped_text, fontsize=50, color='white', size=resolution, method='caption', font=\"Liberation-Sans\"\n",
        "            ).set_position(\"center\").set_duration(sentence_duration).set_start(start_time)\n",
        "            clips.append(txt_clip)\n",
        "            start_time += sentence_duration\n",
        "\n",
        "    # Create blank background\n",
        "    bg_clip = ColorClip(resolution, color=(30, 30, 30), duration=duration)\n",
        "\n",
        "    # Overlay text on background\n",
        "    final_video = CompositeVideoClip([bg_clip] + clips)\n",
        "    final_video = final_video.set_audio(audio)\n",
        "\n",
        "    # Write final video\n",
        "    final_video.write_videofile(video_file, fps=fps, codec=\"libx264\", threads=4, preset=\"ultrafast\")\n",
        "\n",
        "# Generate final video\n",
        "create_video_with_text(audio_file, text, video_file)\n",
        "\n",
        "# 📌 Step 4: Download final video\n",
        "files.download(video_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "id": "qE7MyGoSjVsy",
        "outputId": "93c97025-dbd1-4869-dd2b-2202ac978c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (91.189.91.83)] [Connected to cloud.r-project.org (65.9.86.109\r                                                                                                    \rHit:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "\r                                                                                                    \rHit:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "\r                                                                                                    \rHit:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (91.189.91.83)] [Connecting to r2u.stat.illinois.edu (192.17.1\r                                                                                                    \rHit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Connecting to r2u.stat.illinois.edu (192.17.190.167)] [Connected to ppa.la\r                                                                                                    \rHit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "\r                                                                                                    \r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)]\r                                                                              \rHit:7 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Connected to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers]\r                                                                              \rHit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "imagemagick is already the newest version (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n",
            "Requirement already satisfied: edge-tts in /usr/local/lib/python3.11/dist-packages (7.0.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (3.11.12)\n",
            "Requirement already satisfied: certifi>=2023.11.17 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (2025.1.31)\n",
            "Requirement already satisfied: srt<4.0.0,>=3.4.1 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (3.5.3)\n",
            "Requirement already satisfied: tabulate<1.0.0,>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (4.12.2)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.18.3)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Enter the text for your video: Introduce Yourself - AlmaX Hello everyone, my name is Bharat Gaur, and I am a dedicated Data Scientist from Ghaziabad, Uttar Pradesh. My expertise lies in machine learning, statistical analysis, and extracting meaningful insights from complex datasets to drive data-driven decision-making.\n",
            "Moviepy - Building video final_video.mp4.\n",
            "MoviePy - Writing audio in final_videoTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready final_video.mp4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0d820b70-d9a0-4de0-83cc-97fbc3804c29\", \"final_video.mp4\", 566204)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages (Run this only once)\n",
        "!apt-get update\n",
        "!apt-get install -y imagemagick\n",
        "!sed -i 's/none/read|write/' /etc/ImageMagick-6/policy.xml\n",
        "!pip install edge-tts moviepy\n",
        "\n",
        "import edge_tts\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "from moviepy.editor import *\n",
        "import textwrap\n",
        "\n",
        "# Fix asyncio issue in Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# 📌 Step 1: Input Text (Maintaining Paragraph Formatting)\n",
        "text = \"\"\"Introduce Yourself - AlmaX\n",
        "\n",
        "Hello everyone, my name is Bharat Gaur, and I am a dedicated Data Scientist from Ghaziabad, Uttar Pradesh. My expertise lies in machine learning, statistical analysis, and extracting meaningful insights from complex datasets to drive data-driven decision-making.\n",
        "\n",
        "Academic Background:\n",
        "\n",
        "I have a strong educational foundation in Data Science and Artificial Intelligence. I completed my Master’s in Data Science & AI from IIT Guwahati (in collaboration with AlmaBetter). Before that, I pursued a Bachelor’s degree in Mechanical Engineering from Aligarh College of Engineering & Technology.\n",
        "\n",
        "Technical Skills:\n",
        "\n",
        "I have hands-on experience with multiple programming languages and tools essential for Data Science:\n",
        "\n",
        "Programming Languages: Python and SQL, along with libraries like NumPy and Pandas for data manipulation, and scikit-learn for machine learning.\n",
        "\n",
        "Data Analysis & Visualization Tools: I am skilled in Advanced Excel, Tableau, and Power BI, which help in creating insightful reports and dashboards.\n",
        "\n",
        "Specialized Frameworks: My expertise extends to advanced areas like Machine Learning, Artificial Intelligence, Natural Language Processing (NLP), Deep Learning,\n",
        "Computer Vision, and MLOps, enabling me to work on cutting-edge AI solutions.\n",
        "\"\"\"\n",
        "\n",
        "# Output file names\n",
        "audio_file = \"output_audio.mp3\"\n",
        "video_file = \"final_video.mp4\"\n",
        "\n",
        "# 📌 Step 2: Convert text to speech\n",
        "async def text_to_speech(text, audio_file):\n",
        "    voice = \"en-US-GuyNeural\"  # Male voice\n",
        "    tts = edge_tts.Communicate(text, voice)\n",
        "    await tts.save(audio_file)\n",
        "\n",
        "loop = asyncio.get_event_loop()\n",
        "loop.run_until_complete(text_to_speech(text, audio_file))\n",
        "\n",
        "# 📌 Step 3: Create video with text overlay (Maintaining Exact Formatting)\n",
        "def create_video_with_text(audio_file, text, video_file, resolution=(1280, 720), fps=30):\n",
        "    # Load audio file\n",
        "    audio = AudioFileClip(audio_file)\n",
        "    duration = audio.duration  # Total duration of audio\n",
        "\n",
        "    # Split text into paragraphs (double new line = new paragraph)\n",
        "    paragraphs = text.split(\"\\n\\n\")\n",
        "    num_paragraphs = len(paragraphs)\n",
        "\n",
        "    # Calculate paragraph display time\n",
        "    base_paragraph_duration = duration / num_paragraphs\n",
        "    pause_duration = 1  # 1 second pause between paragraphs\n",
        "\n",
        "    # Create text clips (Paragraph-wise animation with pauses)\n",
        "    clips = []\n",
        "    start_time = 0\n",
        "    for para in paragraphs:\n",
        "        wrapped_text = \"\\n\".join(textwrap.wrap(para, width=40))  # Wrap long text\n",
        "\n",
        "        if wrapped_text:\n",
        "            txt_clip = TextClip(\n",
        "                wrapped_text, fontsize=50, color='white', size=resolution, method='caption', font=\"Liberation-Sans\"\n",
        "            ).set_position(\"center\").set_duration(base_paragraph_duration).set_start(start_time)\n",
        "\n",
        "            clips.append(txt_clip)\n",
        "            start_time += base_paragraph_duration + pause_duration  # Add pause duration\n",
        "\n",
        "    # Create blank background\n",
        "    bg_clip = ColorClip(resolution, color=(30, 30, 30), duration=duration + (pause_duration * num_paragraphs))\n",
        "\n",
        "    # Overlay text on background\n",
        "    final_video = CompositeVideoClip([bg_clip] + clips)\n",
        "    final_video = final_video.set_audio(audio)\n",
        "\n",
        "    # Write final video\n",
        "    final_video.write_videofile(video_file, fps=fps, codec=\"libx264\", threads=4, preset=\"ultrafast\")\n",
        "\n",
        "# Generate final video\n",
        "create_video_with_text(audio_file, text, video_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eZ-6JLbmWYz",
        "outputId": "93554ad5-2c0d-4832-98c8-27c749657c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.81)] [Connecting to cloud.r-p\r                                                                                                    \rHit:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "\r                                                                                                    \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.81)] [Connecting to cloud.r-p\r                                                                                                    \rHit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (91.189.91.81)] [Connecting to cloud.r-project.org] [Connectin\r                                                                                                    \rHit:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to cloud.r-project.org] [Connected to r2u.stat.illinois.edu (19\r                                                                                                    \rHit:6 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to cloud.r-project.org] [Connected to r2u.stat.illinois.edu (19\r                                                                                                    \rHit:7 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:9 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "imagemagick is already the newest version (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n",
            "Requirement already satisfied: edge-tts in /usr/local/lib/python3.11/dist-packages (7.0.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (3.11.12)\n",
            "Requirement already satisfied: certifi>=2023.11.17 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (2025.1.31)\n",
            "Requirement already satisfied: srt<4.0.0,>=3.4.1 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (3.5.3)\n",
            "Requirement already satisfied: tabulate<1.0.0,>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (4.12.2)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.18.3)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Moviepy - Building video final_video.mp4.\n",
            "MoviePy - Writing audio in final_videoTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready final_video.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WjGXZE_Xm668"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages (Run this only once)\n",
        "!apt-get update\n",
        "!apt-get install -y ffmpeg\n",
        "!pip install moviepy openai-whisper\n",
        "\n",
        "import whisper\n",
        "from moviepy.editor import *\n",
        "\n",
        "# 📌 Step 1: Load Pre-recorded Audio\n",
        "audio_file = \"output_audio.mp3\"  # 🔹 Apni audio yahan set karein\n",
        "\n",
        "# 📌 Step 2: Convert Audio to Text using Whisper AI (Automatic Subtitles)\n",
        "model = whisper.load_model(\"small\")  # 🔹 \"small\" model fast & accurate hai\n",
        "result = model.transcribe(audio_file)\n",
        "subtitles = result[\"segments\"]\n",
        "\n",
        "# 📌 Step 3: Create Video with Auto-Synced Text\n",
        "def create_video_with_subtitles(audio_file, subtitles, output_video=\"final_video.mp4\", resolution=(1280, 720), fps=30):\n",
        "    # Load audio\n",
        "    audio = AudioFileClip(audio_file)\n",
        "    duration = audio.duration\n",
        "\n",
        "    # Create blank background\n",
        "    bg_clip = ColorClip(resolution, color=(30, 30, 30), duration=duration)\n",
        "\n",
        "    # Generate subtitles\n",
        "    subtitle_clips = []\n",
        "    for segment in subtitles:\n",
        "        start_time = segment[\"start\"]\n",
        "        end_time = segment[\"end\"]\n",
        "        text = segment[\"text\"]\n",
        "\n",
        "        # Text Clip\n",
        "        txt_clip = TextClip(\n",
        "            text, fontsize=50, color='white', size=(resolution[0] - 100, None), method='caption', font=\"Liberation-Sans\"\n",
        "        ).set_position((\"center\", \"bottom\")).set_duration(end_time - start_time).set_start(start_time)\n",
        "\n",
        "        subtitle_clips.append(txt_clip)\n",
        "\n",
        "    # Overlay subtitles on background\n",
        "    final_video = CompositeVideoClip([bg_clip] + subtitle_clips)\n",
        "    final_video = final_video.set_audio(audio)\n",
        "\n",
        "    # Save final video\n",
        "    final_video.write_videofile(output_video, fps=fps, codec=\"libx264\", threads=4, preset=\"ultrafast\")\n",
        "\n",
        "# Generate video\n",
        "create_video_with_subtitles(audio_file, subtitles)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s8XIFLGPoaZ2",
        "outputId": "43873f2a-5e1f-4964-f5e7-fa1f8347845f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connecting to r2u.stat.illinois.edu] [Connected to d\r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connecting to r2u.stat.illinois.edu (192.17.190.167)\r                                                                                                    \rHit:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connecting to r2u.stat.illinois.edu (192.17.190.167)\r                                                                                                    \rHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connecting to r2u.stat.illinois.edu (192.17.190.167)\r                                                                                                    \rHit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Waiting for headers] [Connecting to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers\r                                                                                                    \rHit:6 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.61.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.5.1+cu124)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.1.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2.0.0->openai-whisper) (3.17.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.44.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m889.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hcanceled\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'whisper'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-79a178a9aa9f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install moviepy openai-whisper'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meditor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'whisper'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required package (Run only once)\n",
        "!apt-get update\n",
        "!apt-get install -y ffmpeg\n",
        "!pip install moviepy\n",
        "\n",
        "import os\n",
        "from moviepy.editor import *\n",
        "\n",
        "# 📌 Step 1: Set Input Audio and Text\n",
        "audio_file = \"output_audio.mp3\"  # 🔹 Apni MP3 file yahan daalein\n",
        "text = \"\"\"\n",
        "Introduce Yourself - AlmaX\n",
        "\n",
        "Hello everyone, my name is Bharat Gaur, and I am a dedicated Data Scientist from Ghaziabad, Uttar Pradesh.\n",
        "\n",
        "My expertise lies in machine learning, statistical analysis, and extracting meaningful insights from complex datasets to drive data-driven decision-making.\n",
        "\n",
        "Academic Background:\n",
        "\n",
        "I have a strong educational foundation in Data Science and Artificial Intelligence. I completed my Master’s in Data Science & AI from IIT Guwahati (in collaboration with AlmaBetter).\n",
        "\n",
        "Before that, I pursued a Bachelor’s degree in Mechanical Engineering from Aligarh College of Engineering & Technology.\n",
        "\"\"\"  # 🔹 Yahan apna text likho\n",
        "\n",
        "# 📌 Step 2: Create Video Background\n",
        "audio = AudioFileClip(audio_file)\n",
        "duration = audio.duration\n",
        "resolution = (1280, 720)\n",
        "\n",
        "# Background video\n",
        "bg_clip = ColorClip(size=resolution, color=(30, 30, 30), duration=duration)\n",
        "\n",
        "# 📌 Step 3: Generate Text Clips (Sentence by Sentence)\n",
        "text_lines = text.split(\"\\n\\n\")  # 🔹 **Double line-break pe paragraph split hoga**\n",
        "sentence_start = 0\n",
        "text_clips = []\n",
        "\n",
        "for line in text_lines:\n",
        "    words_per_second = 2.5  # 🔹 Approximate speed (adjust if needed)\n",
        "    line_duration = len(line.split()) / words_per_second\n",
        "\n",
        "    # Create Text Clip\n",
        "    txt_clip = TextClip(line, fontsize=50, color='white', size=(1200, None), method='caption', font=\"Arial-Bold\")\n",
        "    txt_clip = txt_clip.set_position(('center', 'bottom')).set_duration(line_duration).set_start(sentence_start)\n",
        "\n",
        "    text_clips.append(txt_clip)\n",
        "    sentence_start += line_duration  # Next text after this one\n",
        "\n",
        "# 📌 Step 4: Merge Everything\n",
        "final_video = CompositeVideoClip([bg_clip] + text_clips).set_audio(audio)\n",
        "output_video = \"final_video.mp4\"\n",
        "final_video.write_videofile(output_video, fps=30, codec=\"libx264\", threads=4, preset=\"ultrafast\")\n",
        "\n",
        "print(\"\\n✅ Video successfully generated: final_video.mp4\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRI_lEJLobCi",
        "outputId": "35d9ce62-d216-4e9f-d445-f47480eb9ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.82)] [Connecting to cloud.r-project.org] [Connecting\r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.82)] [Connected to cloud.r-project.org (65.9.86.118)\r                                                                                                    \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Connecting to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers\r                                                                                                    \rHit:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers]\r                                                                                                    \rHit:5 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers]\r                                                                                                    \rHit:6 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "\r                                                                                                    \r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)]\r                                                                              \rHit:7 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.1.31)\n",
            "Moviepy - Building video final_video.mp4.\n",
            "MoviePy - Writing audio in final_videoTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready final_video.mp4\n",
            "\n",
            "✅ Video successfully generated: final_video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AaPiPl8HpIZM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}